{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbtronics/COMP551---Miniproject-3-Classification-of-Image-Data-/blob/main/Group_18_Miniproject_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MskdeYqoN1C9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import pdb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccnXMmu82Kfc"
      },
      "source": [
        "# MLP\n",
        "Multilayer Perceptron Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iheNCxe_FT__"
      },
      "outputs": [],
      "source": [
        "# logistic = lambda z: 1./ (1 + np.exp(-z))\n",
        "# softmax = lambda z: np.exp(-z) / np.sum(np.exp(-z), axis = -1)[:, None]\n",
        "\n",
        "# class MLP:\n",
        "\n",
        "    \n",
        "#   def __init__(self, M = 64):\n",
        "#     self.M = M\n",
        "            \n",
        "#   def fit(self, x, y, optimizer, hidden_layer=1):\n",
        "#     N,D = x.shape\n",
        "#     C = np.max(y)+1\n",
        "#     self.layers = hidden_layer\n",
        "#     y_realprob = np.zeros((N, C))\n",
        "#     for i in range(N): y_realprob[i, y[i]] = 1\n",
        "#     # START: Condition to have 0, 1, 2 layers\n",
        "#     # gradient(x,y,params, hidden_layers)\n",
        "#     def gradient_0layer(x, y, params):\n",
        "#       w = params\n",
        "#       yh = softmax(np.dot(x, w))\n",
        "#       dy = yh - y_realprob # Squared residual loss derivative\n",
        "#       # dw = np.dot(x.T, dy)\n",
        "#       dw = (x.T @ dy)/N\n",
        "#       dparams = [dw]\n",
        "\n",
        "\n",
        "#     def gradient_1layer(x, y, params):\n",
        "#       v, w = params\n",
        "#       z = logistic(np.dot(x, v)) #N x M\n",
        "#       yh = softmax(np.dot(z, w))#N x C\n",
        "#       # print(yh[i, np.argmax(yh[i,:])] for i in range(10))\n",
        "#       # print(y[:10])\n",
        "#       dy = yh - y_realprob #N x C\n",
        "#       dw = np.dot(z.T, dy)/N #M x C\n",
        "#       dz = np.dot(dy, w.T) #N x M\n",
        "#       # print(dz.shape)\n",
        "#       dv = np.dot(x.T, dz * z * (1 - z))/N #D x M\n",
        "#       dparams = [dv, dw]\n",
        "#       return dparams\n",
        "    \n",
        "#     def gradient_2layer(x, y, params):\n",
        "#       return None\n",
        "#     gradient = [gradient_0layer, gradient_1layer, gradient_2layer]\n",
        "        \n",
        "#     # params0 = [np.random.randn(self.M) for i in range(hidden_layer+1)]\n",
        "#     if(hidden_layer==0):\n",
        "#       w = np.random.randn(D, C) # weights b/w I/O\n",
        "#       params0 = [w]\n",
        "#     elif (hidden_layer==1):\n",
        "#       v = np.random.randn(D, self.M) # weights b/w I/first layer\n",
        "#       w = np.random.randn(self.M, C) # weights b/w first/second layer\n",
        "#       params0 = [v, w]\n",
        "#     elif (hidden_layer==2):\n",
        "#       v = np.random.randn(D, self.M) # weights b/w I/first layer\n",
        "#       r = np.random.randn(self.M, self.M) # weights b/w first/second layer\n",
        "#       w = np.random.randn(self.M, C) # weights b/w second/O layer\n",
        "#       params = [v, r, w]\n",
        "#     else: \n",
        "#       print(\"hidden layer should be <= 2\")\n",
        "#       return None\n",
        "#     # END: Condition to have 0, 1, 2 layers\n",
        "#     self.params = optimizer.run(gradient[hidden_layer], x, y, params0)\n",
        "#     return self\n",
        "    \n",
        "#   def predict(self, x): # Tweak this method too\n",
        "#     if(self.layers==0):\n",
        "#       w = self.params\n",
        "#       yh = softmax(np.dot(x, w))\n",
        "#       return None\n",
        "#     elif(self.layers==1):\n",
        "#       v, w = self.params\n",
        "#       z = logistic(np.dot(x, v)) # N x M\n",
        "#       yh = logistic(np.dot(z, w)) # N x C\n",
        "#     elif(self.layers==2):\n",
        "#       v, r, w = self.params\n",
        "#       h1 = logistic(np.dot(x, v))\n",
        "#       h2 = logistic(np.dot(h1, r))\n",
        "#       yh = softmax(np.dot(h2, w))\n",
        "#     else:\n",
        "#       print(\"Error\")\n",
        "#       return None\n",
        "#     print(yh[:10])\n",
        "#     y_pred = [np.argmax(yh[i, :]) for i in range(x.shape[0])]\n",
        "#     return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Wmtl4tPwduk6"
      },
      "outputs": [],
      "source": [
        "class MLP:\n",
        "  def __init__ (self, input_neurons, output_neurons, epochs=int(1e3), hidden_layer=1,\n",
        "               hidden_neurons=128,learning_rate=1e-2, epsilon=1e-3, activation=\"sigmoid\"):\n",
        "    self.epochs = epochs\n",
        "    self.hidden_layer = hidden_layer\n",
        "    self.input_neurons = input_neurons\n",
        "    self.hidden_neurons = hidden_neurons\n",
        "    self.output_neurons = output_neurons\n",
        "    self.learning_rate = learning_rate\n",
        "    self.epsilon=epsilon\n",
        "    self.activation=activation\n",
        "    # no. of weights dependent on hidden_layers\n",
        "    self.weights = self.init_weights(self.hidden_layer)\n",
        "\n",
        "  def init_weights(self, hidden_layer):\n",
        "    if(hidden_layer==0):\n",
        "      w = np.random.randn(self.input_neurons, self.output_neurons) * np.sqrt(1./self.output_neurons)\n",
        "      return np.asarray(w)\n",
        "    elif (hidden_layer==1):\n",
        "      v = np.random.randn(self.input_neurons, self.hidden_neurons) * np.sqrt(1./self.hidden_neurons)\n",
        "      w = np.random.randn(self.hidden_neurons, self.output_neurons) * np.sqrt(1./self.output_neurons)\n",
        "      return np.asarray([v,w])\n",
        "    elif (hidden_layer==2):\n",
        "      v = np.random.randn(self.input_neurons, self.hidden_neurons) * np.sqrt(1./self.hidden_neurons)\n",
        "      r = np.random.randn(self.hidden_neurons, self.hidden_neurons) * np.sqrt(1./self.hidden_neurons)\n",
        "      w = np.random.randn(self.hidden_neurons, self.output_neurons) * np.sqrt(1./self.output_neurons)\n",
        "      return np.asarray([v,r,w])\n",
        "    else:\n",
        "      print(\"# of hidden layer should be <= 2\")\n",
        "      return None\n",
        "\n",
        "  def fit(self, x_train, y_train):\n",
        "    y_class = np.zeros((y_train.shape[0], np.max(y_train)+1))\n",
        "    for i in range(y_train.shape[0]): y_class[i,y_train[i]] = 1\n",
        "    \n",
        "    norm = np.array([np.inf])\n",
        "    t=0\n",
        "    while(np.any(norm>self.epsilon) and t<self.epochs):\n",
        "      # pdb.set_trace()\n",
        "      yh = self.forward_pass(x_train)\n",
        "      dweights = self.back_prop(yh, y_class)\n",
        "      # print(dweights)\n",
        "      self.update_weights(np.asarray(dweights))\n",
        "      norm = np.array([np.linalg.norm(g) for g in dweights])\n",
        "      print(\"Epoch: \", t, \" with accuracy of: \", self.eval_acc(np.argmax(yh, axis=-1), y_train))\n",
        "      print(\"Norm: \", norm)\n",
        "      t+=1\n",
        "\n",
        "  def activation_function(self, z, derivative=False):\n",
        "    if(self.activation==\"sigmoid\"):\n",
        "      if derivative: return sigmoid(z)*(1-sigmoid(z))\n",
        "      else: return sigmoid(z)\n",
        "    elif(self.activation==\"tanh\"):\n",
        "      if derivative: return 1-np.square(tanh(z))\n",
        "      else: return tanh(z)\n",
        "    elif(self.activation==\"relu\"):\n",
        "      if derivative: return 1 * (z>0)\n",
        "      else: return relu(z)\n",
        "    elif(self.activation==\"leaky-relu\"):\n",
        "      if derivative:\n",
        "        return 1 if (z>0) else 0.1\n",
        "      else: return leaky_relu(z)\n",
        "    else:\n",
        "      print(\"invalid activation function\")\n",
        "      return None\n",
        "  def forward_pass(self, x_train):\n",
        "    f1 = x_train # N x D\n",
        "    self.f_params = []\n",
        "    if(self.hidden_layer==0):\n",
        "      # input --> output\n",
        "      f2 = np.dot(f1, self.weight[0]) # N x C\n",
        "      f3 = softmax(f2) # N x C\n",
        "      self.f_params = [f1, f2, f3]\n",
        "      return f3\n",
        "\n",
        "    elif (self.hidden_layer==1):\n",
        "      # input --> first layer\n",
        "      f2 = np.dot(f1, self.weights[0]) # N x M\n",
        "      f3 = self.activation_function(f2) # N x M\n",
        "\n",
        "      # first layer --> output\n",
        "      f4 = np.dot(f3, self.weights[1]) # N x C\n",
        "      f5 = softmax(f4) # N x C\n",
        "      # print(\"f1\", f1[:3])\n",
        "      # print(\"f2\", f2[:3])\n",
        "      # print(\"f3\", f3[:3])\n",
        "      # print(\"f4\", f4[:3])\n",
        "      # print(\"f5\", f5[:3])\n",
        "      self.f_params = [f1, f2, f3, f4, f5]\n",
        "      return f5\n",
        "\n",
        "    elif (self.hidden_layer==2):\n",
        "      # input --> first layer\n",
        "      f2 = np.dot(f1, self.weight[0]) # N x M\n",
        "      f3 = self.activation_function(f2) # N x M\n",
        "\n",
        "      # first layer --> second layer\n",
        "      f4 = np.dot(f3, self.weight[1]) # N x M\n",
        "      f5 = self.activation_function(f4) # N x M\n",
        "\n",
        "      # second layer --> output\n",
        "      f6 = np.dot(f5, self.weight[2]) # N x C\n",
        "      f7 = softmax(f6) # N x C\n",
        "      self.f_params = [f1, f2, f3, f4, f5, f6, f7]\n",
        "      return f7\n",
        "    \n",
        "    else:\n",
        "      print(\"No forward pass\")\n",
        "      return None\n",
        "\n",
        "  \n",
        "  def back_prop(self, y_pred, y_train):\n",
        "    N = y_pred.shape[0]\n",
        "    b1 = y_pred-y_train # N x C\n",
        "    # print('y_pred', y_pred[:3])\n",
        "    # print('p_train', y_train[:3])\n",
        "    if(self.hidden_layer==0):\n",
        "      f1, f2, f3 = self.f_params\n",
        "\n",
        "      e1 = b1 * softmax_diff(f2) # N x C\n",
        "      b2 = np.dot(f1.T, e1)/N # D x C\n",
        "\n",
        "      return b2\n",
        "\n",
        "    elif (self.hidden_layer==1):\n",
        "      f1, f2, f3, f4, f5 = self.f_params\n",
        "      # print(\"b1\", b1[:3])\n",
        "      # print(\"f4\", f4[:3])\n",
        "      e1 = b1 * softmax_diff(f4) # N x C\n",
        "      b2 = np.dot(f3.T, e1)/N # M x C\n",
        "      # print(\"e1\", e1[:3])\n",
        "      # print(\"f3\", f3[:3])\n",
        "      # print(\"b2\", b2[:3])\n",
        "      b3 = np.dot(e1, self.weights[1].T) # N x M\n",
        "\n",
        "      e2 = self.activation_function(f2, derivative=True)\n",
        "      b4 = np.dot(f1.T, b3*e2)/N # D x M\n",
        "      # print(\"b4\", b4[:3])\n",
        "      # print(\"b2\", b2[:3])\n",
        "      return [b4, b2]\n",
        "\n",
        "    elif (self.hidden_layer==2):\n",
        "      f1, f2, f3, f4, f5, f6, f7 = self.f_params\n",
        "\n",
        "      e1 = b1 * softmax_diff(f6) # N x C\n",
        "      b2 = np.dot(f5.T, e1)/N # M x C\n",
        "\n",
        "      b3 = np.dot(e1, self.weights[2].T) # N x M\n",
        "\n",
        "      e2 = self.activation_function(f4, derivative=True) # N x M\n",
        "      b4 = np.dot((b3*e2).T, f3)/N # M x M\n",
        "\n",
        "      b5 = np.dot(b3*e2, self.weights[1].T) # N x M\n",
        "\n",
        "      e3 = self.activation_function(f2, derivative=True) # N x M\n",
        "      b6 = np.dot(f1.T, (b5*e3))/N # D x M\n",
        "\n",
        "      return [b6, b4, b2]\n",
        "    \n",
        "    else:\n",
        "      print(\"No backpropagation\")\n",
        "      return None\n",
        "  \n",
        "  def update_weights(self, dweights):\n",
        "    self.weights -= self.learning_rate * dweights\n",
        "\n",
        "  def predict(self, x_test):\n",
        "    yh = self.forward_pass(x_test)\n",
        "    return np.argmax(yh, axis=-1)\n",
        "\n",
        "  def eval_acc(self, y_pred, y_test):\n",
        "    acc = y_pred==y_test\n",
        "    # print(\"Prediction: 0 --> %d ; 1 --> %d ; 2 --> %d ; 3 --> %d ; 4 --> %d ; 5 --> %d ; 6 --> %d ; 7 --> %d ; 8 --> %d ; 9 --> %d\"  % (np.sum(y_pred == 0), np.sum(y_pred==1), np.sum(y_pred==2), np.sum(y_pred==3), np.sum(y_pred==4), np.sum(y_pred==5), np.sum(y_pred==6), np.sum(y_pred==7), np.sum(y_pred==8), np.sum(y_pred==9)))\n",
        "    return np.sum(acc)/len(y_test)\n",
        "    # return(np.mean((y_pred==y_test)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VItK1k56dvsZ"
      },
      "source": [
        "## Activation Function\n",
        "Sigmoid, ReLu, Leaky ReLu, tanh for intermediate layer \n",
        "\n",
        "Softmax and derivative for classification and gradient update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "F-oYE_F6cu4E"
      },
      "outputs": [],
      "source": [
        "sigmoid = lambda z: 1./ (1 + np.exp(-z))\n",
        "# sigmoid_diff = lambda z: sigmoid(z)*(1-sigmoid(z))\n",
        "\n",
        "relu = lambda z: np.maximum(0, z)\n",
        "\n",
        "tanh = lambda z: np.tanh(z)\n",
        "\n",
        "leaky_relu = lambda z: np.maximum(0.1*z, z)\n",
        "\n",
        "softmax = lambda z: np.exp(z-z.max()) / np.sum(np.exp(z-z.max()), axis = -1)[:, None]\n",
        "softmax_diff = lambda z: softmax(z)*(1-softmax(z))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JLv0x3XqHGB3"
      },
      "outputs": [],
      "source": [
        "# def eval_acc(y_pred, y_real):\n",
        "#   if(y_pred.ndim==1 and y_real.ndim==1): \n",
        "#     # print(y_pred[:5])\n",
        "#     # print(y_real[:5])\n",
        "#     print(np.max(y_pred))\n",
        "#     print(np.sum(y_pred==y_real))\n",
        "#     print(len(y_pred))\n",
        "#     return np.sum(y_pred==y_real)/len(y_pred)\n",
        "#   else: \n",
        "#     print(\"dimension should be 1\")\n",
        "#     return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKfv0Lsv2WcW"
      },
      "source": [
        "## Gradient Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jr5KoRKL2acW"
      },
      "outputs": [],
      "source": [
        "# class GradientDescent:\n",
        "    \n",
        "#   def __init__(self, learning_rate=.001, max_iters=1e4, epsilon=1e-8):\n",
        "#     self.learning_rate = learning_rate\n",
        "#     self.max_iters = max_iters\n",
        "#     self.epsilon = epsilon\n",
        "        \n",
        "#   def run(self, gradient_fn, x, y, params):\n",
        "#     norms = np.array([np.inf])\n",
        "#     t = 1\n",
        "#     while np.any(norms > self.epsilon) and t < self.max_iters:\n",
        "#       # add parameter of number of layers\n",
        "#         grad = gradient_fn(x, y, params)\n",
        "#         for p in range(len(params)):\n",
        "#             params[p] -= self.learning_rate * grad[p]\n",
        "#         t += 1\n",
        "#         norms = np.array([np.linalg.norm(g) for g in grad])\n",
        "#         print(\"%d epoch completed with norm of:\" %(t))\n",
        "#         print(norms)\n",
        "#     return params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N4SfaBsfX4C"
      },
      "source": [
        "# Main Body of Code\n",
        "## Importing Data and normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwHaJAg0Iwp4",
        "outputId": "dd0229d0-c9ff-4b9d-b95a-736a8b73b52a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train image shape:  (60000, 28, 28)\n",
            "Train label shape:  (60000,)\n",
            "\n",
            "Test image shape:  (10000, 28, 28)\n",
            "Test label shape:  (10000,)\n",
            "(6000, 784)\n",
            "(600, 784)\n",
            "(5400, 784)\n"
          ]
        }
      ],
      "source": [
        "mnist_dataset = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist_dataset.load_data()\n",
        "\n",
        "print(\"Train image shape: \", train_images.shape)\n",
        "print(\"Train label shape: \", train_labels.shape)\n",
        "print(\"\\nTest image shape: \", test_images.shape)\n",
        "print(\"Test label shape: \", test_labels.shape)\n",
        "\n",
        "train_images = train_images/255\n",
        "test_images = test_images/255\n",
        "\n",
        "fraction = 0.10 # 10% validation and 90% training set\n",
        "n_train = train_images.shape[0]\n",
        "# w, h = train_images[0].shape\n",
        "train_images = train_images[:int(fraction*n_train)]\n",
        "train_labels = train_labels[:int(fraction*n_train)]\n",
        "train_images = train_images.reshape(train_images.shape[0], -1)\n",
        "print(train_images.shape)\n",
        "\n",
        "n_train = train_images.shape[0]\n",
        "x_test = train_images[:int(fraction*n_train)]\n",
        "y_test = train_labels[:int(fraction*n_train)]\n",
        "print(x_test.shape)\n",
        "\n",
        "x_train = train_images[int(fraction*n_train):]\n",
        "y_train = train_labels[int(fraction*n_train):]\n",
        "print(x_train.shape)\n",
        "# plt.imshow(train_images[10], cmap='gray')\n",
        "# plt.colorbar()\n",
        "# plt.grid(False)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SECVORJh-VnZ",
        "outputId": "cac473d2-f9a9-4f62-e81a-177342fffb17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0  with accuracy of:  0.029444444444444443\n",
            "Norm:  [2.01736851 0.63059389]\n",
            "Epoch:  1  with accuracy of:  0.04111111111111111\n",
            "Norm:  [1.94507432 0.61490543]\n",
            "Epoch:  2  with accuracy of:  0.0512962962962963\n",
            "Norm:  [1.84178305 0.59307266]\n",
            "Epoch:  3  with accuracy of:  0.05925925925925926\n",
            "Norm:  [1.73541934 0.57111063]\n",
            "Epoch:  4  with accuracy of:  0.06814814814814815\n",
            "Norm:  [1.63846018 0.55104846]\n",
            "Epoch:  5  with accuracy of:  0.07388888888888889\n",
            "Norm:  [1.55278192 0.53243958]\n",
            "Epoch:  6  with accuracy of:  0.07759259259259259\n",
            "Norm:  [1.47516827 0.51437106]\n",
            "Epoch:  7  with accuracy of:  0.08203703703703703\n",
            "Norm:  [1.40404983 0.49622572]\n",
            "Epoch:  8  with accuracy of:  0.08481481481481482\n",
            "Norm:  [1.33760809 0.47774457]\n",
            "Epoch:  9  with accuracy of:  0.08981481481481482\n",
            "Norm:  [1.27358382 0.45900095]\n",
            "Epoch:  10  with accuracy of:  0.09314814814814815\n",
            "Norm:  [1.21344565 0.44027252]\n",
            "Epoch:  11  with accuracy of:  0.09574074074074074\n",
            "Norm:  [1.15581457 0.42187796]\n",
            "Epoch:  12  with accuracy of:  0.09814814814814815\n",
            "Norm:  [1.10177385 0.40414779]\n",
            "Epoch:  13  with accuracy of:  0.09870370370370371\n",
            "Norm:  [1.05101749 0.38740864]\n",
            "Epoch:  14  with accuracy of:  0.10018518518518518\n",
            "Norm:  [1.00511347 0.37183581]\n",
            "Epoch:  15  with accuracy of:  0.10388888888888889\n",
            "Norm:  [0.96221045 0.35751773]\n",
            "Epoch:  16  with accuracy of:  0.10537037037037036\n",
            "Norm:  [0.92384228 0.34452762]\n",
            "Epoch:  17  with accuracy of:  0.10722222222222222\n",
            "Norm:  [0.88925301 0.3328149 ]\n",
            "Epoch:  18  with accuracy of:  0.10944444444444444\n",
            "Norm:  [0.85757182 0.32230855]\n",
            "Epoch:  19  with accuracy of:  0.10925925925925926\n",
            "Norm:  [0.82851869 0.31293826]\n",
            "Epoch:  20  with accuracy of:  0.11092592592592593\n",
            "Norm:  [0.8032529  0.30456184]\n",
            "Epoch:  21  with accuracy of:  0.11277777777777778\n",
            "Norm:  [0.77988694 0.2970698 ]\n",
            "Epoch:  22  with accuracy of:  0.11388888888888889\n",
            "Norm:  [0.75890821 0.29034149]\n",
            "Epoch:  23  with accuracy of:  0.11388888888888889\n",
            "Norm:  [0.7404402  0.28426317]\n",
            "Epoch:  24  with accuracy of:  0.11333333333333333\n",
            "Norm:  [0.72322253 0.27875837]\n",
            "Epoch:  25  with accuracy of:  0.11444444444444445\n",
            "Norm:  [0.70715489 0.27376248]\n",
            "Epoch:  26  with accuracy of:  0.11537037037037037\n",
            "Norm:  [0.69309612 0.26920536]\n",
            "Epoch:  27  with accuracy of:  0.11648148148148148\n",
            "Norm:  [0.67877887 0.26502329]\n",
            "Epoch:  28  with accuracy of:  0.11722222222222223\n",
            "Norm:  [0.6660812  0.26118236]\n",
            "Epoch:  29  with accuracy of:  0.11814814814814815\n",
            "Norm:  [0.65417364 0.25764075]\n",
            "Epoch:  30  with accuracy of:  0.12018518518518519\n",
            "Norm:  [0.64425497 0.25436805]\n",
            "Epoch:  31  with accuracy of:  0.12018518518518519\n",
            "Norm:  [0.63488403 0.25132243]\n",
            "Epoch:  32  with accuracy of:  0.12055555555555555\n",
            "Norm:  [0.62557611 0.2484807 ]\n",
            "Epoch:  33  with accuracy of:  0.12148148148148148\n",
            "Norm:  [0.6165889  0.24582796]\n",
            "Epoch:  34  with accuracy of:  0.12222222222222222\n",
            "Norm:  [0.60843883 0.24334809]\n",
            "Epoch:  35  with accuracy of:  0.12314814814814815\n",
            "Norm:  [0.60040376 0.2410185 ]\n",
            "Epoch:  36  with accuracy of:  0.12555555555555556\n",
            "Norm:  [0.59237881 0.23882901]\n",
            "Epoch:  37  with accuracy of:  0.12703703703703703\n",
            "Norm:  [0.5853019  0.23678668]\n",
            "Epoch:  38  with accuracy of:  0.12796296296296297\n",
            "Norm:  [0.57799281 0.23487093]\n",
            "Epoch:  39  with accuracy of:  0.12851851851851853\n",
            "Norm:  [0.57153818 0.2330735 ]\n",
            "Epoch:  40  with accuracy of:  0.13055555555555556\n",
            "Norm:  [0.56604278 0.23137933]\n",
            "Epoch:  41  with accuracy of:  0.13185185185185186\n",
            "Norm:  [0.5608856  0.22978223]\n",
            "Epoch:  42  with accuracy of:  0.13333333333333333\n",
            "Norm:  [0.55563585 0.22826747]\n",
            "Epoch:  43  with accuracy of:  0.135\n",
            "Norm:  [0.55097614 0.22682971]\n",
            "Epoch:  44  with accuracy of:  0.1361111111111111\n",
            "Norm:  [0.54594378 0.22546635]\n",
            "Epoch:  45  with accuracy of:  0.1374074074074074\n",
            "Norm:  [0.54182081 0.2241805 ]\n",
            "Epoch:  46  with accuracy of:  0.13944444444444445\n",
            "Norm:  [0.53795124 0.22295161]\n",
            "Epoch:  47  with accuracy of:  0.1411111111111111\n",
            "Norm:  [0.53364203 0.22178811]\n",
            "Epoch:  48  with accuracy of:  0.14203703703703704\n",
            "Norm:  [0.52947721 0.22068368]\n",
            "Epoch:  49  with accuracy of:  0.1438888888888889\n",
            "Norm:  [0.52594729 0.21964017]\n",
            "Epoch:  50  with accuracy of:  0.1461111111111111\n",
            "Norm:  [0.52209403 0.21864625]\n",
            "Epoch:  51  with accuracy of:  0.14833333333333334\n",
            "Norm:  [0.51872955 0.21769932]\n",
            "Epoch:  52  with accuracy of:  0.15018518518518517\n",
            "Norm:  [0.51534    0.21679476]\n",
            "Epoch:  53  with accuracy of:  0.15037037037037038\n",
            "Norm:  [0.51272707 0.21592993]\n",
            "Epoch:  54  with accuracy of:  0.15222222222222223\n",
            "Norm:  [0.51015723 0.21509203]\n",
            "Epoch:  55  with accuracy of:  0.1537037037037037\n",
            "Norm:  [0.50764485 0.21428364]\n",
            "Epoch:  56  with accuracy of:  0.15407407407407409\n",
            "Norm:  [0.50439954 0.2135068 ]\n",
            "Epoch:  57  with accuracy of:  0.15518518518518518\n",
            "Norm:  [0.50159274 0.21275535]\n",
            "Epoch:  58  with accuracy of:  0.1575925925925926\n",
            "Norm:  [0.49921269 0.21203953]\n",
            "Epoch:  59  with accuracy of:  0.15888888888888889\n",
            "Norm:  [0.49672038 0.21134981]\n",
            "Epoch:  60  with accuracy of:  0.15981481481481483\n",
            "Norm:  [0.49385698 0.21068501]\n",
            "Epoch:  61  with accuracy of:  0.16074074074074074\n",
            "Norm:  [0.49152448 0.21004103]\n",
            "Epoch:  62  with accuracy of:  0.16166666666666665\n",
            "Norm:  [0.48930108 0.20941464]\n",
            "Epoch:  63  with accuracy of:  0.16314814814814815\n",
            "Norm:  [0.48725287 0.20880483]\n",
            "Epoch:  64  with accuracy of:  0.16462962962962963\n",
            "Norm:  [0.48579288 0.20821046]\n",
            "Epoch:  65  with accuracy of:  0.16592592592592592\n",
            "Norm:  [0.48363646 0.20762718]\n",
            "Epoch:  66  with accuracy of:  0.16814814814814816\n",
            "Norm:  [0.48142497 0.20705599]\n",
            "Epoch:  67  with accuracy of:  0.17\n",
            "Norm:  [0.47965851 0.20649634]\n",
            "Epoch:  68  with accuracy of:  0.17074074074074075\n",
            "Norm:  [0.47796218 0.20594337]\n",
            "Epoch:  69  with accuracy of:  0.1725925925925926\n",
            "Norm:  [0.47644814 0.20539595]\n",
            "Epoch:  70  with accuracy of:  0.17537037037037037\n",
            "Norm:  [0.47457439 0.20485779]\n",
            "Epoch:  71  with accuracy of:  0.17629629629629628\n",
            "Norm:  [0.47304401 0.2043265 ]\n",
            "Epoch:  72  with accuracy of:  0.17777777777777778\n",
            "Norm:  [0.47113372 0.20380161]\n",
            "Epoch:  73  with accuracy of:  0.17851851851851852\n",
            "Norm:  [0.46902762 0.20328246]\n",
            "Epoch:  74  with accuracy of:  0.18\n",
            "Norm:  [0.46741913 0.20277269]\n",
            "Epoch:  75  with accuracy of:  0.18037037037037038\n",
            "Norm:  [0.46562485 0.20226807]\n",
            "Epoch:  76  with accuracy of:  0.18185185185185185\n",
            "Norm:  [0.46395993 0.20177371]\n",
            "Epoch:  77  with accuracy of:  0.18222222222222223\n",
            "Norm:  [0.46256864 0.20128215]\n",
            "Epoch:  78  with accuracy of:  0.18351851851851853\n",
            "Norm:  [0.46099205 0.20078962]\n",
            "Epoch:  79  with accuracy of:  0.18425925925925926\n",
            "Norm:  [0.45908748 0.20029807]\n",
            "Epoch:  80  with accuracy of:  0.185\n",
            "Norm:  [0.4573844  0.19981499]\n",
            "Epoch:  81  with accuracy of:  0.18611111111111112\n",
            "Norm:  [0.45593482 0.19933746]\n",
            "Epoch:  82  with accuracy of:  0.1875925925925926\n",
            "Norm:  [0.45435144 0.19886363]\n",
            "Epoch:  83  with accuracy of:  0.18907407407407406\n",
            "Norm:  [0.45258849 0.1983932 ]\n",
            "Epoch:  84  with accuracy of:  0.19\n",
            "Norm:  [0.45118624 0.19792555]\n",
            "Epoch:  85  with accuracy of:  0.19166666666666668\n",
            "Norm:  [0.44944587 0.19745929]\n",
            "Epoch:  86  with accuracy of:  0.19407407407407407\n",
            "Norm:  [0.4479411  0.19699681]\n",
            "Epoch:  87  with accuracy of:  0.19518518518518518\n",
            "Norm:  [0.44668339 0.19653511]\n",
            "Epoch:  88  with accuracy of:  0.1962962962962963\n",
            "Norm:  [0.44517579 0.19607702]\n",
            "Epoch:  89  with accuracy of:  0.19666666666666666\n",
            "Norm:  [0.44368006 0.1956203 ]\n",
            "Epoch:  90  with accuracy of:  0.1975925925925926\n",
            "Norm:  [0.44184578 0.19516533]\n",
            "Epoch:  91  with accuracy of:  0.19907407407407407\n",
            "Norm:  [0.44008785 0.19471611]\n",
            "Epoch:  92  with accuracy of:  0.2\n",
            "Norm:  [0.4384885  0.19427174]\n",
            "Epoch:  93  with accuracy of:  0.20185185185185187\n",
            "Norm:  [0.43726139 0.19382956]\n",
            "Epoch:  94  with accuracy of:  0.20277777777777778\n",
            "Norm:  [0.43638972 0.19338722]\n",
            "Epoch:  95  with accuracy of:  0.2037037037037037\n",
            "Norm:  [0.43525563 0.19294352]\n",
            "Epoch:  96  with accuracy of:  0.20462962962962963\n",
            "Norm:  [0.43401879 0.19249906]\n",
            "Epoch:  97  with accuracy of:  0.2051851851851852\n",
            "Norm:  [0.43264649 0.19205766]\n",
            "Epoch:  98  with accuracy of:  0.2061111111111111\n",
            "Norm:  [0.43163601 0.19161674]\n",
            "Epoch:  99  with accuracy of:  0.2064814814814815\n",
            "Norm:  [0.43049245 0.19117176]\n",
            "Epoch:  100  with accuracy of:  0.2075925925925926\n",
            "Norm:  [0.42913366 0.19072941]\n",
            "Epoch:  101  with accuracy of:  0.20814814814814814\n",
            "Norm:  [0.42791886 0.19029144]\n",
            "Epoch:  102  with accuracy of:  0.20944444444444443\n",
            "Norm:  [0.42634897 0.1898565 ]\n",
            "Epoch:  103  with accuracy of:  0.21074074074074073\n",
            "Norm:  [0.42524216 0.18942506]\n",
            "Epoch:  104  with accuracy of:  0.2124074074074074\n",
            "Norm:  [0.42370375 0.18899577]\n",
            "Epoch:  105  with accuracy of:  0.21222222222222223\n",
            "Norm:  [0.42241935 0.18856866]\n",
            "Epoch:  106  with accuracy of:  0.21314814814814814\n",
            "Norm:  [0.42105865 0.18814277]\n",
            "Epoch:  107  with accuracy of:  0.21388888888888888\n",
            "Norm:  [0.41946522 0.1877215 ]\n",
            "Epoch:  108  with accuracy of:  0.215\n",
            "Norm:  [0.4178122  0.18730556]\n",
            "Epoch:  109  with accuracy of:  0.21666666666666667\n",
            "Norm:  [0.41656537 0.18689556]\n",
            "Epoch:  110  with accuracy of:  0.2175925925925926\n",
            "Norm:  [0.41543761 0.1864885 ]\n",
            "Epoch:  111  with accuracy of:  0.2187037037037037\n",
            "Norm:  [0.41415331 0.18607864]\n",
            "Epoch:  112  with accuracy of:  0.22\n",
            "Norm:  [0.41300776 0.18567191]\n",
            "Epoch:  113  with accuracy of:  0.22037037037037038\n",
            "Norm:  [0.41146158 0.18526337]\n",
            "Epoch:  114  with accuracy of:  0.22185185185185186\n",
            "Norm:  [0.41027256 0.18485708]\n",
            "Epoch:  115  with accuracy of:  0.22333333333333333\n",
            "Norm:  [0.40875268 0.18445235]\n",
            "Epoch:  116  with accuracy of:  0.22407407407407406\n",
            "Norm:  [0.4076396  0.18404665]\n",
            "Epoch:  117  with accuracy of:  0.225\n",
            "Norm:  [0.40647337 0.18363912]\n",
            "Epoch:  118  with accuracy of:  0.22611111111111112\n",
            "Norm:  [0.40525017 0.18323177]\n",
            "Epoch:  119  with accuracy of:  0.2262962962962963\n",
            "Norm:  [0.40399001 0.18282429]\n",
            "Epoch:  120  with accuracy of:  0.22666666666666666\n",
            "Norm:  [0.40271425 0.18241798]\n",
            "Epoch:  121  with accuracy of:  0.22648148148148148\n",
            "Norm:  [0.40187125 0.1820135 ]\n",
            "Epoch:  122  with accuracy of:  0.22777777777777777\n",
            "Norm:  [0.40051992 0.18160748]\n",
            "Epoch:  123  with accuracy of:  0.22944444444444445\n",
            "Norm:  [0.39934573 0.18120358]\n",
            "Epoch:  124  with accuracy of:  0.2301851851851852\n",
            "Norm:  [0.39807401 0.18079826]\n",
            "Epoch:  125  with accuracy of:  0.23148148148148148\n",
            "Norm:  [0.39682433 0.18039304]\n",
            "Epoch:  126  with accuracy of:  0.2325925925925926\n",
            "Norm:  [0.39561713 0.17998397]\n",
            "Epoch:  127  with accuracy of:  0.2337037037037037\n",
            "Norm:  [0.39430185 0.17957308]\n",
            "Epoch:  128  with accuracy of:  0.2348148148148148\n",
            "Norm:  [0.39318642 0.1791617 ]\n",
            "Epoch:  129  with accuracy of:  0.2351851851851852\n",
            "Norm:  [0.39201732 0.17874864]\n",
            "Epoch:  130  with accuracy of:  0.23555555555555555\n",
            "Norm:  [0.39082915 0.17833505]\n",
            "Epoch:  131  with accuracy of:  0.23666666666666666\n",
            "Norm:  [0.3897757  0.17791958]\n",
            "Epoch:  132  with accuracy of:  0.23796296296296296\n",
            "Norm:  [0.38861993 0.17750295]\n",
            "Epoch:  133  with accuracy of:  0.2388888888888889\n",
            "Norm:  [0.38721178 0.1770921 ]\n",
            "Epoch:  134  with accuracy of:  0.24074074074074073\n",
            "Norm:  [0.38576388 0.17668284]\n",
            "Epoch:  135  with accuracy of:  0.24092592592592593\n",
            "Norm:  [0.38481873 0.17628055]\n",
            "Epoch:  136  with accuracy of:  0.24222222222222223\n",
            "Norm:  [0.38388001 0.1758787 ]\n",
            "Epoch:  137  with accuracy of:  0.2437037037037037\n",
            "Norm:  [0.38262636 0.17547477]\n",
            "Epoch:  138  with accuracy of:  0.24425925925925926\n",
            "Norm:  [0.38155136 0.17507282]\n",
            "Epoch:  139  with accuracy of:  0.245\n",
            "Norm:  [0.38053824 0.1746715 ]\n",
            "Epoch:  140  with accuracy of:  0.2461111111111111\n",
            "Norm:  [0.37938362 0.17427132]\n",
            "Epoch:  141  with accuracy of:  0.24703703703703703\n",
            "Norm:  [0.37853845 0.17387104]\n",
            "Epoch:  142  with accuracy of:  0.24851851851851853\n",
            "Norm:  [0.37757921 0.17347064]\n",
            "Epoch:  143  with accuracy of:  0.24962962962962962\n",
            "Norm:  [0.37638248 0.17306961]\n",
            "Epoch:  144  with accuracy of:  0.25\n",
            "Norm:  [0.37517655 0.1726708 ]\n",
            "Epoch:  145  with accuracy of:  0.2511111111111111\n",
            "Norm:  [0.37423077 0.17227397]\n",
            "Epoch:  146  with accuracy of:  0.2514814814814815\n",
            "Norm:  [0.3731309  0.17187826]\n",
            "Epoch:  147  with accuracy of:  0.25222222222222224\n",
            "Norm:  [0.37188281 0.17148031]\n",
            "Epoch:  148  with accuracy of:  0.25296296296296295\n",
            "Norm:  [0.37088273 0.17108706]\n",
            "Epoch:  149  with accuracy of:  0.255\n",
            "Norm:  [0.36979546 0.17069194]\n",
            "Epoch:  150  with accuracy of:  0.25555555555555554\n",
            "Norm:  [0.36839846 0.17029992]\n",
            "Epoch:  151  with accuracy of:  0.2561111111111111\n",
            "Norm:  [0.36719794 0.16990844]\n",
            "Epoch:  152  with accuracy of:  0.25722222222222224\n",
            "Norm:  [0.36623245 0.16951992]\n",
            "Epoch:  153  with accuracy of:  0.2581481481481481\n",
            "Norm:  [0.36520375 0.16913253]\n",
            "Epoch:  154  with accuracy of:  0.2587037037037037\n",
            "Norm:  [0.36388804 0.16874892]\n",
            "Epoch:  155  with accuracy of:  0.2601851851851852\n",
            "Norm:  [0.36267251 0.16836972]\n",
            "Epoch:  156  with accuracy of:  0.2611111111111111\n",
            "Norm:  [0.36163212 0.16799314]\n",
            "Epoch:  157  with accuracy of:  0.2625925925925926\n",
            "Norm:  [0.36048185 0.16761819]\n",
            "Epoch:  158  with accuracy of:  0.2633333333333333\n",
            "Norm:  [0.35960287 0.16724733]\n",
            "Epoch:  159  with accuracy of:  0.26425925925925925\n",
            "Norm:  [0.35867158 0.16687542]\n",
            "Epoch:  160  with accuracy of:  0.26537037037037037\n",
            "Norm:  [0.35764738 0.1665102 ]\n",
            "Epoch:  161  with accuracy of:  0.2664814814814815\n",
            "Norm:  [0.35643144 0.16614644]\n",
            "Epoch:  162  with accuracy of:  0.267037037037037\n",
            "Norm:  [0.35552964 0.16578692]\n",
            "Epoch:  163  with accuracy of:  0.2675925925925926\n",
            "Norm:  [0.35457302 0.16543012]\n",
            "Epoch:  164  with accuracy of:  0.2690740740740741\n",
            "Norm:  [0.35352848 0.16507475]\n",
            "Epoch:  165  with accuracy of:  0.27055555555555555\n",
            "Norm:  [0.35264615 0.16472088]\n",
            "Epoch:  166  with accuracy of:  0.27111111111111114\n",
            "Norm:  [0.35153604 0.1643694 ]\n",
            "Epoch:  167  with accuracy of:  0.2727777777777778\n",
            "Norm:  [0.35051627 0.16402063]\n",
            "Epoch:  168  with accuracy of:  0.2737037037037037\n",
            "Norm:  [0.3493468  0.16367422]\n",
            "Epoch:  169  with accuracy of:  0.2746296296296296\n",
            "Norm:  [0.34827556 0.16333009]\n",
            "Epoch:  170  with accuracy of:  0.2751851851851852\n",
            "Norm:  [0.34723557 0.16298994]\n",
            "Epoch:  171  with accuracy of:  0.27574074074074073\n",
            "Norm:  [0.34623192 0.16265203]\n",
            "Epoch:  172  with accuracy of:  0.2764814814814815\n",
            "Norm:  [0.34524659 0.16231589]\n",
            "Epoch:  173  with accuracy of:  0.27814814814814814\n",
            "Norm:  [0.34404895 0.16198631]\n",
            "Epoch:  174  with accuracy of:  0.2790740740740741\n",
            "Norm:  [0.34325908 0.16165772]\n",
            "Epoch:  175  with accuracy of:  0.2798148148148148\n",
            "Norm:  [0.34227907 0.16133046]\n",
            "Epoch:  176  with accuracy of:  0.2812962962962963\n",
            "Norm:  [0.34133614 0.16100659]\n",
            "Epoch:  177  with accuracy of:  0.28185185185185185\n",
            "Norm:  [0.34012086 0.16068278]\n",
            "Epoch:  178  with accuracy of:  0.28296296296296297\n",
            "Norm:  [0.33914291 0.16036014]\n",
            "Epoch:  179  with accuracy of:  0.2838888888888889\n",
            "Norm:  [0.33795822 0.16003973]\n",
            "Epoch:  180  with accuracy of:  0.28444444444444444\n",
            "Norm:  [0.3369571  0.15971838]\n",
            "Epoch:  181  with accuracy of:  0.2853703703703704\n",
            "Norm:  [0.33600104 0.15939644]\n",
            "Epoch:  182  with accuracy of:  0.28555555555555556\n",
            "Norm:  [0.3350795  0.15907934]\n",
            "Epoch:  183  with accuracy of:  0.28574074074074074\n",
            "Norm:  [0.33407443 0.15876134]\n",
            "Epoch:  184  with accuracy of:  0.2872222222222222\n",
            "Norm:  [0.33309006 0.15844121]\n",
            "Epoch:  185  with accuracy of:  0.287962962962963\n",
            "Norm:  [0.33235634 0.15812223]\n",
            "Epoch:  186  with accuracy of:  0.28888888888888886\n",
            "Norm:  [0.33148221 0.15780505]\n",
            "Epoch:  187  with accuracy of:  0.2890740740740741\n",
            "Norm:  [0.3308331  0.15748499]\n",
            "Epoch:  188  with accuracy of:  0.29\n",
            "Norm:  [0.32997898 0.15716801]\n",
            "Epoch:  189  with accuracy of:  0.2903703703703704\n",
            "Norm:  [0.3291722  0.15684918]\n",
            "Epoch:  190  with accuracy of:  0.29074074074074074\n",
            "Norm:  [0.32823071 0.15652742]\n",
            "Epoch:  191  with accuracy of:  0.2914814814814815\n",
            "Norm:  [0.3272502  0.15620535]\n",
            "Epoch:  192  with accuracy of:  0.2922222222222222\n",
            "Norm:  [0.32635277 0.15588416]\n",
            "Epoch:  193  with accuracy of:  0.292962962962963\n",
            "Norm:  [0.32566477 0.15556329]\n",
            "Epoch:  194  with accuracy of:  0.2935185185185185\n",
            "Norm:  [0.32470932 0.15524125]\n",
            "Epoch:  195  with accuracy of:  0.295\n",
            "Norm:  [0.32386636 0.15491763]\n",
            "Epoch:  196  with accuracy of:  0.2953703703703704\n",
            "Norm:  [0.32304917 0.15459384]\n",
            "Epoch:  197  with accuracy of:  0.2966666666666667\n",
            "Norm:  [0.32205211 0.15427007]\n",
            "Epoch:  198  with accuracy of:  0.29703703703703704\n",
            "Norm:  [0.32134892 0.15394653]\n",
            "Epoch:  199  with accuracy of:  0.2975925925925926\n",
            "Norm:  [0.32052568 0.15361811]\n",
            "Epoch:  200  with accuracy of:  0.29888888888888887\n",
            "Norm:  [0.31971184 0.15329067]\n",
            "Epoch:  201  with accuracy of:  0.2998148148148148\n",
            "Norm:  [0.31903185 0.15295961]\n",
            "Epoch:  202  with accuracy of:  0.3005555555555556\n",
            "Norm:  [0.31820493 0.15262665]\n",
            "Epoch:  203  with accuracy of:  0.3011111111111111\n",
            "Norm:  [0.31741835 0.15229082]\n",
            "Epoch:  204  with accuracy of:  0.3016666666666667\n",
            "Norm:  [0.31655258 0.1519533 ]\n",
            "Epoch:  205  with accuracy of:  0.3025925925925926\n",
            "Norm:  [0.31564166 0.15161245]\n",
            "Epoch:  206  with accuracy of:  0.302962962962963\n",
            "Norm:  [0.31466896 0.15126923]\n",
            "Epoch:  207  with accuracy of:  0.30333333333333334\n",
            "Norm:  [0.31381169 0.15092235]\n",
            "Epoch:  208  with accuracy of:  0.3042592592592593\n",
            "Norm:  [0.31296315 0.15057107]\n",
            "Epoch:  209  with accuracy of:  0.30462962962962964\n",
            "Norm:  [0.3120502  0.15021855]\n",
            "Epoch:  210  with accuracy of:  0.30518518518518517\n",
            "Norm:  [0.31139432 0.14986227]\n",
            "Epoch:  211  with accuracy of:  0.3061111111111111\n",
            "Norm:  [0.31049992 0.14950004]\n",
            "Epoch:  212  with accuracy of:  0.3068518518518519\n",
            "Norm:  [0.30967908 0.1491354 ]\n",
            "Epoch:  213  with accuracy of:  0.30814814814814817\n",
            "Norm:  [0.30884404 0.14876966]\n",
            "Epoch:  214  with accuracy of:  0.3088888888888889\n",
            "Norm:  [0.30799939 0.14839915]\n",
            "Epoch:  215  with accuracy of:  0.30925925925925923\n",
            "Norm:  [0.30721472 0.14802248]\n",
            "Epoch:  216  with accuracy of:  0.3101851851851852\n",
            "Norm:  [0.30633403 0.14764211]\n",
            "Epoch:  217  with accuracy of:  0.31055555555555553\n",
            "Norm:  [0.30538202 0.14725833]\n",
            "Epoch:  218  with accuracy of:  0.3111111111111111\n",
            "Norm:  [0.30461206 0.14687147]\n",
            "Epoch:  219  with accuracy of:  0.31166666666666665\n",
            "Norm:  [0.30376341 0.14648207]\n",
            "Epoch:  220  with accuracy of:  0.31222222222222223\n",
            "Norm:  [0.30283097 0.14608937]\n",
            "Epoch:  221  with accuracy of:  0.31277777777777777\n",
            "Norm:  [0.30198549 0.14569013]\n",
            "Epoch:  222  with accuracy of:  0.31333333333333335\n",
            "Norm:  [0.30125619 0.1452866 ]\n",
            "Epoch:  223  with accuracy of:  0.3138888888888889\n",
            "Norm:  [0.30038437 0.14487737]\n",
            "Epoch:  224  with accuracy of:  0.31462962962962965\n",
            "Norm:  [0.29958608 0.14446574]\n",
            "Epoch:  225  with accuracy of:  0.3161111111111111\n",
            "Norm:  [0.2986544  0.14405118]\n",
            "Epoch:  226  with accuracy of:  0.3164814814814815\n",
            "Norm:  [0.29772805 0.14363174]\n",
            "Epoch:  227  with accuracy of:  0.31722222222222224\n",
            "Norm:  [0.29682775 0.14321082]\n",
            "Epoch:  228  with accuracy of:  0.3175925925925926\n",
            "Norm:  [0.29612716 0.14278526]\n",
            "Epoch:  229  with accuracy of:  0.31851851851851853\n",
            "Norm:  [0.29530126 0.14235368]\n",
            "Epoch:  230  with accuracy of:  0.31981481481481483\n",
            "Norm:  [0.29440629 0.14191621]\n",
            "Epoch:  231  with accuracy of:  0.32037037037037036\n",
            "Norm:  [0.29339713 0.14147327]\n",
            "Epoch:  232  with accuracy of:  0.32185185185185183\n",
            "Norm:  [0.29246081 0.14102557]\n",
            "Epoch:  233  with accuracy of:  0.32222222222222224\n",
            "Norm:  [0.29158846 0.14057137]\n",
            "Epoch:  234  with accuracy of:  0.32314814814814813\n",
            "Norm:  [0.2908192  0.14011321]\n",
            "Epoch:  235  with accuracy of:  0.32351851851851854\n",
            "Norm:  [0.28986198 0.13965361]\n",
            "Epoch:  236  with accuracy of:  0.32407407407407407\n",
            "Norm:  [0.28897024 0.13918717]\n",
            "Epoch:  237  with accuracy of:  0.32425925925925925\n",
            "Norm:  [0.28811717 0.13871311]\n",
            "Epoch:  238  with accuracy of:  0.32537037037037037\n",
            "Norm:  [0.28717341 0.13823552]\n",
            "Epoch:  239  with accuracy of:  0.32611111111111113\n",
            "Norm:  [0.28629547 0.13775312]\n",
            "Epoch:  240  with accuracy of:  0.32722222222222225\n",
            "Norm:  [0.28542405 0.13726619]\n",
            "Epoch:  241  with accuracy of:  0.3274074074074074\n",
            "Norm:  [0.28457601 0.13677255]\n",
            "Epoch:  242  with accuracy of:  0.3287037037037037\n",
            "Norm:  [0.28366807 0.13627483]\n",
            "Epoch:  243  with accuracy of:  0.3288888888888889\n",
            "Norm:  [0.28283366 0.13577295]\n",
            "Epoch:  244  with accuracy of:  0.3301851851851852\n",
            "Norm:  [0.28206003 0.13526739]\n",
            "Epoch:  245  with accuracy of:  0.33055555555555555\n",
            "Norm:  [0.28124587 0.13475464]\n",
            "Epoch:  246  with accuracy of:  0.3309259259259259\n",
            "Norm:  [0.28036833 0.13423805]\n",
            "Epoch:  247  with accuracy of:  0.3312962962962963\n",
            "Norm:  [0.27957747 0.13371428]\n",
            "Epoch:  248  with accuracy of:  0.33166666666666667\n",
            "Norm:  [0.27862619 0.13318496]\n",
            "Epoch:  249  with accuracy of:  0.3322222222222222\n",
            "Norm:  [0.27786492 0.13264906]\n",
            "Epoch:  250  with accuracy of:  0.33314814814814814\n",
            "Norm:  [0.27702964 0.13210916]\n",
            "Epoch:  251  with accuracy of:  0.3338888888888889\n",
            "Norm:  [0.27610933 0.13156226]\n",
            "Epoch:  252  with accuracy of:  0.3348148148148148\n",
            "Norm:  [0.27530465 0.13101195]\n",
            "Epoch:  253  with accuracy of:  0.33555555555555555\n",
            "Norm:  [0.27449084 0.13045865]\n",
            "Epoch:  254  with accuracy of:  0.33611111111111114\n",
            "Norm:  [0.27356442 0.12990181]\n",
            "Epoch:  255  with accuracy of:  0.3359259259259259\n",
            "Norm:  [0.27268489 0.12934228]\n",
            "Epoch:  256  with accuracy of:  0.3362962962962963\n",
            "Norm:  [0.27163865 0.128782  ]\n",
            "Epoch:  257  with accuracy of:  0.33666666666666667\n",
            "Norm:  [0.27078881 0.12821825]\n",
            "Epoch:  258  with accuracy of:  0.337037037037037\n",
            "Norm:  [0.26985546 0.12764989]\n",
            "Epoch:  259  with accuracy of:  0.337037037037037\n",
            "Norm:  [0.26903367 0.12707658]\n",
            "Epoch:  260  with accuracy of:  0.33740740740740743\n",
            "Norm:  [0.26818358 0.12650296]\n",
            "Epoch:  261  with accuracy of:  0.3383333333333333\n",
            "Norm:  [0.26719989 0.12592787]\n",
            "Epoch:  262  with accuracy of:  0.3388888888888889\n",
            "Norm:  [0.26626291 0.12534908]\n",
            "Epoch:  263  with accuracy of:  0.34\n",
            "Norm:  [0.26548899 0.12476731]\n",
            "Epoch:  264  with accuracy of:  0.3411111111111111\n",
            "Norm:  [0.2646425  0.12418273]\n",
            "Epoch:  265  with accuracy of:  0.3427777777777778\n",
            "Norm:  [0.26382321 0.12359707]\n",
            "Epoch:  266  with accuracy of:  0.3433333333333333\n",
            "Norm:  [0.2629796  0.12300855]\n",
            "Epoch:  267  with accuracy of:  0.34444444444444444\n",
            "Norm:  [0.26221261 0.1224145 ]\n",
            "Epoch:  268  with accuracy of:  0.345\n",
            "Norm:  [0.2613581  0.12181648]\n",
            "Epoch:  269  with accuracy of:  0.34629629629629627\n",
            "Norm:  [0.26053672 0.12121459]\n",
            "Epoch:  270  with accuracy of:  0.3472222222222222\n",
            "Norm:  [0.25970291 0.12061087]\n",
            "Epoch:  271  with accuracy of:  0.3475925925925926\n",
            "Norm:  [0.25874425 0.12000589]\n",
            "Epoch:  272  with accuracy of:  0.3487037037037037\n",
            "Norm:  [0.25783846 0.11940018]\n",
            "Epoch:  273  with accuracy of:  0.3487037037037037\n",
            "Norm:  [0.25699217 0.11879692]\n",
            "Epoch:  274  with accuracy of:  0.3496296296296296\n",
            "Norm:  [0.25613755 0.11819345]\n",
            "Epoch:  275  with accuracy of:  0.35\n",
            "Norm:  [0.2553376  0.11758895]\n",
            "Epoch:  276  with accuracy of:  0.3514814814814815\n",
            "Norm:  [0.2544817  0.11698605]\n",
            "Epoch:  277  with accuracy of:  0.35259259259259257\n",
            "Norm:  [0.25361437 0.11638339]\n",
            "Epoch:  278  with accuracy of:  0.3537037037037037\n",
            "Norm:  [0.25273217 0.1157819 ]\n",
            "Epoch:  279  with accuracy of:  0.3542592592592593\n",
            "Norm:  [0.25200734 0.11518062]\n",
            "Epoch:  280  with accuracy of:  0.3561111111111111\n",
            "Norm:  [0.25117626 0.11457954]\n",
            "Epoch:  281  with accuracy of:  0.3574074074074074\n",
            "Norm:  [0.250302   0.11397787]\n",
            "Epoch:  282  with accuracy of:  0.35888888888888887\n",
            "Norm:  [0.24938433 0.11338165]\n",
            "Epoch:  283  with accuracy of:  0.35944444444444446\n",
            "Norm:  [0.24859182 0.11278629]\n",
            "Epoch:  284  with accuracy of:  0.36\n",
            "Norm:  [0.24768573 0.11219159]\n",
            "Epoch:  285  with accuracy of:  0.36\n",
            "Norm:  [0.24678072 0.11160235]\n",
            "Epoch:  286  with accuracy of:  0.36\n",
            "Norm:  [0.24603876 0.11101385]\n",
            "Epoch:  287  with accuracy of:  0.36074074074074075\n",
            "Norm:  [0.24526201 0.11042804]\n",
            "Epoch:  288  with accuracy of:  0.3612962962962963\n",
            "Norm:  [0.24439294 0.10984681]\n",
            "Epoch:  289  with accuracy of:  0.36203703703703705\n",
            "Norm:  [0.2436851  0.10926641]\n",
            "Epoch:  290  with accuracy of:  0.36333333333333334\n",
            "Norm:  [0.24288045 0.10868639]\n",
            "Epoch:  291  with accuracy of:  0.3638888888888889\n",
            "Norm:  [0.24212716 0.10810609]\n",
            "Epoch:  292  with accuracy of:  0.36462962962962964\n",
            "Norm:  [0.24134401 0.10752745]\n",
            "Epoch:  293  with accuracy of:  0.365\n",
            "Norm:  [0.2404633  0.10695078]\n",
            "Epoch:  294  with accuracy of:  0.3668518518518519\n",
            "Norm:  [0.23967043 0.10637769]\n",
            "Epoch:  295  with accuracy of:  0.3668518518518519\n",
            "Norm:  [0.23888201 0.10580765]\n",
            "Epoch:  296  with accuracy of:  0.36777777777777776\n",
            "Norm:  [0.23799171 0.10523939]\n",
            "Epoch:  297  with accuracy of:  0.3685185185185185\n",
            "Norm:  [0.23723288 0.1046737 ]\n",
            "Epoch:  298  with accuracy of:  0.36925925925925923\n",
            "Norm:  [0.23647768 0.10411089]\n",
            "Epoch:  299  with accuracy of:  0.3705555555555556\n",
            "Norm:  [0.23575061 0.1035508 ]\n",
            "Epoch:  300  with accuracy of:  0.37222222222222223\n",
            "Norm:  [0.23506548 0.10299454]\n",
            "Epoch:  301  with accuracy of:  0.37277777777777776\n",
            "Norm:  [0.23441105 0.10244032]\n",
            "Epoch:  302  with accuracy of:  0.3737037037037037\n",
            "Norm:  [0.23362898 0.10188941]\n",
            "Epoch:  303  with accuracy of:  0.37425925925925924\n",
            "Norm:  [0.23292496 0.10134224]\n",
            "Epoch:  304  with accuracy of:  0.37537037037037035\n",
            "Norm:  [0.23218873 0.10079646]\n",
            "Epoch:  305  with accuracy of:  0.3764814814814815\n",
            "Norm:  [0.2314096  0.10025296]\n",
            "Epoch:  306  with accuracy of:  0.3774074074074074\n",
            "Norm:  [0.23064797 0.09971182]\n",
            "Epoch:  307  with accuracy of:  0.37777777777777777\n",
            "Norm:  [0.22986341 0.09917334]\n",
            "Epoch:  308  with accuracy of:  0.37833333333333335\n",
            "Norm:  [0.22921524 0.09863834]\n",
            "Epoch:  309  with accuracy of:  0.3788888888888889\n",
            "Norm:  [0.2284413  0.09810568]\n",
            "Epoch:  310  with accuracy of:  0.37925925925925924\n",
            "Norm:  [0.22775115 0.09757704]\n",
            "Epoch:  311  with accuracy of:  0.3798148148148148\n",
            "Norm:  [0.22699969 0.09705123]\n",
            "Epoch:  312  with accuracy of:  0.38037037037037036\n",
            "Norm:  [0.22631335 0.09652802]\n",
            "Epoch:  313  with accuracy of:  0.38203703703703706\n",
            "Norm:  [0.22570431 0.09600726]\n",
            "Epoch:  314  with accuracy of:  0.3827777777777778\n",
            "Norm:  [0.22514486 0.0954894 ]\n",
            "Epoch:  315  with accuracy of:  0.3831481481481481\n",
            "Norm:  [0.22438821 0.09497491]\n",
            "Epoch:  316  with accuracy of:  0.38351851851851854\n",
            "Norm:  [0.22368169 0.09446296]\n",
            "Epoch:  317  with accuracy of:  0.38425925925925924\n",
            "Norm:  [0.22300095 0.09395425]\n",
            "Epoch:  318  with accuracy of:  0.38425925925925924\n",
            "Norm:  [0.22232201 0.09344751]\n",
            "Epoch:  319  with accuracy of:  0.38462962962962965\n",
            "Norm:  [0.22176441 0.09294257]\n",
            "Epoch:  320  with accuracy of:  0.38537037037037036\n",
            "Norm:  [0.22118746 0.09244017]\n",
            "Epoch:  321  with accuracy of:  0.387037037037037\n",
            "Norm:  [0.22050577 0.09193933]\n",
            "Epoch:  322  with accuracy of:  0.3875925925925926\n",
            "Norm:  [0.21992956 0.09144176]\n",
            "Epoch:  323  with accuracy of:  0.38796296296296295\n",
            "Norm:  [0.21935355 0.09094552]\n",
            "Epoch:  324  with accuracy of:  0.38851851851851854\n",
            "Norm:  [0.21873812 0.09045128]\n",
            "Epoch:  325  with accuracy of:  0.39\n",
            "Norm:  [0.21819328 0.08995981]\n",
            "Epoch:  326  with accuracy of:  0.39055555555555554\n",
            "Norm:  [0.21762791 0.08947071]\n",
            "Epoch:  327  with accuracy of:  0.39111111111111113\n",
            "Norm:  [0.21714784 0.08898293]\n",
            "Epoch:  328  with accuracy of:  0.3925925925925926\n",
            "Norm:  [0.21656125 0.08849647]\n",
            "Epoch:  329  with accuracy of:  0.3925925925925926\n",
            "Norm:  [0.21608644 0.08801345]\n",
            "Epoch:  330  with accuracy of:  0.3937037037037037\n",
            "Norm:  [0.21552596 0.08753207]\n",
            "Epoch:  331  with accuracy of:  0.3959259259259259\n",
            "Norm:  [0.21500008 0.08705288]\n",
            "Epoch:  332  with accuracy of:  0.3975925925925926\n",
            "Norm:  [0.21452953 0.08657511]\n",
            "Epoch:  333  with accuracy of:  0.39814814814814814\n",
            "Norm:  [0.21404122 0.08609835]\n",
            "Epoch:  334  with accuracy of:  0.3987037037037037\n",
            "Norm:  [0.21343317 0.08562422]\n",
            "Epoch:  335  with accuracy of:  0.3990740740740741\n",
            "Norm:  [0.21295493 0.0851532 ]\n",
            "Epoch:  336  with accuracy of:  0.4001851851851852\n",
            "Norm:  [0.21245526 0.08468328]\n",
            "Epoch:  337  with accuracy of:  0.4012962962962963\n",
            "Norm:  [0.21197062 0.08421657]\n",
            "Epoch:  338  with accuracy of:  0.4024074074074074\n",
            "Norm:  [0.21152277 0.08375169]\n",
            "Epoch:  339  with accuracy of:  0.4025925925925926\n",
            "Norm:  [0.21113317 0.08328997]\n",
            "Epoch:  340  with accuracy of:  0.4027777777777778\n",
            "Norm:  [0.21069218 0.08283007]\n",
            "Epoch:  341  with accuracy of:  0.40314814814814814\n",
            "Norm:  [0.21035331 0.08237262]\n",
            "Epoch:  342  with accuracy of:  0.4040740740740741\n",
            "Norm:  [0.20994675 0.08191665]\n",
            "Epoch:  343  with accuracy of:  0.4046296296296296\n",
            "Norm:  [0.20949326 0.08146272]\n",
            "Epoch:  344  with accuracy of:  0.4048148148148148\n",
            "Norm:  [0.20911702 0.08101191]\n",
            "Epoch:  345  with accuracy of:  0.4053703703703704\n",
            "Norm:  [0.20885962 0.08056365]\n",
            "Epoch:  346  with accuracy of:  0.4059259259259259\n",
            "Norm:  [0.20860168 0.08011695]\n",
            "Epoch:  347  with accuracy of:  0.4088888888888889\n",
            "Norm:  [0.20835316 0.07967278]\n",
            "Epoch:  348  with accuracy of:  0.4098148148148148\n",
            "Norm:  [0.20806804 0.07923113]\n",
            "Epoch:  349  with accuracy of:  0.41055555555555556\n",
            "Norm:  [0.20778841 0.0787906 ]\n",
            "Epoch:  350  with accuracy of:  0.4111111111111111\n",
            "Norm:  [0.20749717 0.07835242]\n",
            "Epoch:  351  with accuracy of:  0.41185185185185186\n",
            "Norm:  [0.20728137 0.07791715]\n",
            "Epoch:  352  with accuracy of:  0.4122222222222222\n",
            "Norm:  [0.20704983 0.07748544]\n",
            "Epoch:  353  with accuracy of:  0.41314814814814815\n",
            "Norm:  [0.20686212 0.07705778]\n",
            "Epoch:  354  with accuracy of:  0.4135185185185185\n",
            "Norm:  [0.20663961 0.07663353]\n",
            "Epoch:  355  with accuracy of:  0.41444444444444445\n",
            "Norm:  [0.20653514 0.07621211]\n",
            "Epoch:  356  with accuracy of:  0.41574074074074074\n",
            "Norm:  [0.20644821 0.07579371]\n",
            "Epoch:  357  with accuracy of:  0.4159259259259259\n",
            "Norm:  [0.20628288 0.07537936]\n",
            "Epoch:  358  with accuracy of:  0.4164814814814815\n",
            "Norm:  [0.20607699 0.07497023]\n",
            "Epoch:  359  with accuracy of:  0.41703703703703704\n",
            "Norm:  [0.20595861 0.07456617]\n",
            "Epoch:  360  with accuracy of:  0.4172222222222222\n",
            "Norm:  [0.20599521 0.07416605]\n",
            "Epoch:  361  with accuracy of:  0.41833333333333333\n",
            "Norm:  [0.20592845 0.07377124]\n",
            "Epoch:  362  with accuracy of:  0.4190740740740741\n",
            "Norm:  [0.20587699 0.07338091]\n",
            "Epoch:  363  with accuracy of:  0.4198148148148148\n",
            "Norm:  [0.20593495 0.07299709]\n",
            "Epoch:  364  with accuracy of:  0.42055555555555557\n",
            "Norm:  [0.20597567 0.07261975]\n",
            "Epoch:  365  with accuracy of:  0.4209259259259259\n",
            "Norm:  [0.20610197 0.0722498 ]\n",
            "Epoch:  366  with accuracy of:  0.4216666666666667\n",
            "Norm:  [0.20615237 0.07188663]\n",
            "Epoch:  367  with accuracy of:  0.422962962962963\n",
            "Norm:  [0.20632821 0.0715322 ]\n",
            "Epoch:  368  with accuracy of:  0.42407407407407405\n",
            "Norm:  [0.20658566 0.07118532]\n",
            "Epoch:  369  with accuracy of:  0.4248148148148148\n",
            "Norm:  [0.20677531 0.07084859]\n",
            "Epoch:  370  with accuracy of:  0.42592592592592593\n",
            "Norm:  [0.20701677 0.07052168]\n",
            "Epoch:  371  with accuracy of:  0.4266666666666667\n",
            "Norm:  [0.20733247 0.07020378]\n",
            "Epoch:  372  with accuracy of:  0.4272222222222222\n",
            "Norm:  [0.20762004 0.06989666]\n",
            "Epoch:  373  with accuracy of:  0.4285185185185185\n",
            "Norm:  [0.20799666 0.06960082]\n",
            "Epoch:  374  with accuracy of:  0.4298148148148148\n",
            "Norm:  [0.2083971  0.06931664]\n",
            "Epoch:  375  with accuracy of:  0.43092592592592593\n",
            "Norm:  [0.20869023 0.06904554]\n",
            "Epoch:  376  with accuracy of:  0.43314814814814817\n",
            "Norm:  [0.20917188 0.06878866]\n",
            "Epoch:  377  with accuracy of:  0.43407407407407406\n",
            "Norm:  [0.20959802 0.06854809]\n",
            "Epoch:  378  with accuracy of:  0.43555555555555553\n",
            "Norm:  [0.21007131 0.06832423]\n",
            "Epoch:  379  with accuracy of:  0.43703703703703706\n",
            "Norm:  [0.21050251 0.06811751]\n",
            "Epoch:  380  with accuracy of:  0.43722222222222223\n",
            "Norm:  [0.21109875 0.06792972]\n",
            "Epoch:  381  with accuracy of:  0.43925925925925924\n",
            "Norm:  [0.21166289 0.06775993]\n",
            "Epoch:  382  with accuracy of:  0.44074074074074077\n",
            "Norm:  [0.21231569 0.06761014]\n",
            "Epoch:  383  with accuracy of:  0.44166666666666665\n",
            "Norm:  [0.2128433  0.06748198]\n",
            "Epoch:  384  with accuracy of:  0.44222222222222224\n",
            "Norm:  [0.21350205 0.06737716]\n",
            "Epoch:  385  with accuracy of:  0.44351851851851853\n",
            "Norm:  [0.21405588 0.06729621]\n",
            "Epoch:  386  with accuracy of:  0.4437037037037037\n",
            "Norm:  [0.21486471 0.06723975]\n",
            "Epoch:  387  with accuracy of:  0.44462962962962965\n",
            "Norm:  [0.21571518 0.06720957]\n",
            "Epoch:  388  with accuracy of:  0.4461111111111111\n",
            "Norm:  [0.21656809 0.06720555]\n",
            "Epoch:  389  with accuracy of:  0.4464814814814815\n",
            "Norm:  [0.2174727 0.0672322]\n",
            "Epoch:  390  with accuracy of:  0.44796296296296295\n",
            "Norm:  [0.21849507 0.06728963]\n",
            "Epoch:  391  with accuracy of:  0.44925925925925925\n",
            "Norm:  [0.21957595 0.06737904]\n",
            "Epoch:  392  with accuracy of:  0.45037037037037037\n",
            "Norm:  [0.22059821 0.0675009 ]\n",
            "Epoch:  393  with accuracy of:  0.4512962962962963\n",
            "Norm:  [0.2215597  0.06765803]\n",
            "Epoch:  394  with accuracy of:  0.452037037037037\n",
            "Norm:  [0.22264771 0.06785318]\n",
            "Epoch:  395  with accuracy of:  0.45351851851851854\n",
            "Norm:  [0.22376673 0.06808687]\n",
            "Epoch:  396  with accuracy of:  0.455\n",
            "Norm:  [0.22492905 0.06836011]\n",
            "Epoch:  397  with accuracy of:  0.4557407407407407\n",
            "Norm:  [0.226097   0.06867338]\n",
            "Epoch:  398  with accuracy of:  0.457037037037037\n",
            "Norm:  [0.22755353 0.06902964]\n",
            "Epoch:  399  with accuracy of:  0.45944444444444443\n",
            "Norm:  [0.22882819 0.06942775]\n",
            "Epoch:  400  with accuracy of:  0.46074074074074073\n",
            "Norm:  [0.2301447 0.0698708]\n",
            "Epoch:  401  with accuracy of:  0.46111111111111114\n",
            "Norm:  [0.2315685  0.07035888]\n",
            "Epoch:  402  with accuracy of:  0.4633333333333333\n",
            "Norm:  [0.23289279 0.07089405]\n",
            "Epoch:  403  with accuracy of:  0.4648148148148148\n",
            "Norm:  [0.23426078 0.07147453]\n",
            "Epoch:  404  with accuracy of:  0.46703703703703703\n",
            "Norm:  [0.23562958 0.07210244]\n",
            "Epoch:  405  with accuracy of:  0.46814814814814815\n",
            "Norm:  [0.23709247 0.07277752]\n",
            "Epoch:  406  with accuracy of:  0.4696296296296296\n",
            "Norm:  [0.23868432 0.07349924]\n",
            "Epoch:  407  with accuracy of:  0.4709259259259259\n",
            "Norm:  [0.24027457 0.07426681]\n",
            "Epoch:  408  with accuracy of:  0.47185185185185186\n",
            "Norm:  [0.24206182 0.07507803]\n",
            "Epoch:  409  with accuracy of:  0.4737037037037037\n",
            "Norm:  [0.24371027 0.07593246]\n",
            "Epoch:  410  with accuracy of:  0.47574074074074074\n",
            "Norm:  [0.24539525 0.07682742]\n",
            "Epoch:  411  with accuracy of:  0.4774074074074074\n",
            "Norm:  [0.24708998 0.07776326]\n",
            "Epoch:  412  with accuracy of:  0.47833333333333333\n",
            "Norm:  [0.24882295 0.0787363 ]\n",
            "Epoch:  413  with accuracy of:  0.4812962962962963\n",
            "Norm:  [0.25075356 0.07974443]\n",
            "Epoch:  414  with accuracy of:  0.4835185185185185\n",
            "Norm:  [0.2525508  0.08078094]\n",
            "Epoch:  415  with accuracy of:  0.4861111111111111\n",
            "Norm:  [0.25430268 0.08183958]\n",
            "Epoch:  416  with accuracy of:  0.4874074074074074\n",
            "Norm:  [0.25623074 0.08291709]\n",
            "Epoch:  417  with accuracy of:  0.487962962962963\n",
            "Norm:  [0.25816291 0.08400718]\n",
            "Epoch:  418  with accuracy of:  0.4898148148148148\n",
            "Norm:  [0.26007411 0.08510325]\n",
            "Epoch:  419  with accuracy of:  0.49277777777777776\n",
            "Norm:  [0.26200175 0.0862012 ]\n",
            "Epoch:  420  with accuracy of:  0.49462962962962964\n",
            "Norm:  [0.26394541 0.08729231]\n",
            "Epoch:  421  with accuracy of:  0.49648148148148147\n",
            "Norm:  [0.26565806 0.08836814]\n",
            "Epoch:  422  with accuracy of:  0.4998148148148148\n",
            "Norm:  [0.26756036 0.0894218 ]\n",
            "Epoch:  423  with accuracy of:  0.5025925925925926\n",
            "Norm:  [0.26926396 0.09044338]\n",
            "Epoch:  424  with accuracy of:  0.5048148148148148\n",
            "Norm:  [0.270886   0.09142335]\n",
            "Epoch:  425  with accuracy of:  0.5077777777777778\n",
            "Norm:  [0.27240615 0.0923572 ]\n",
            "Epoch:  426  with accuracy of:  0.5101851851851852\n",
            "Norm:  [0.27375604 0.09323567]\n",
            "Epoch:  427  with accuracy of:  0.5114814814814815\n",
            "Norm:  [0.27517807 0.09404832]\n",
            "Epoch:  428  with accuracy of:  0.5140740740740741\n",
            "Norm:  [0.27662591 0.09479257]\n",
            "Epoch:  429  with accuracy of:  0.5164814814814814\n",
            "Norm:  [0.27779856 0.0954604 ]\n",
            "Epoch:  430  with accuracy of:  0.5198148148148148\n",
            "Norm:  [0.27877421 0.0960439 ]\n",
            "Epoch:  431  with accuracy of:  0.5224074074074074\n",
            "Norm:  [0.27952775 0.09654156]\n",
            "Epoch:  432  with accuracy of:  0.5266666666666666\n",
            "Norm:  [0.28016988 0.09695125]\n",
            "Epoch:  433  with accuracy of:  0.5298148148148148\n",
            "Norm:  [0.28064548 0.09726604]\n",
            "Epoch:  434  with accuracy of:  0.5335185185185185\n",
            "Norm:  [0.28098418 0.0974888 ]\n",
            "Epoch:  435  with accuracy of:  0.5357407407407407\n",
            "Norm:  [0.28127473 0.09762053]\n",
            "Epoch:  436  with accuracy of:  0.5381481481481482\n",
            "Norm:  [0.28124936 0.09766216]\n",
            "Epoch:  437  with accuracy of:  0.5416666666666666\n",
            "Norm:  [0.28114682 0.09761698]\n",
            "Epoch:  438  with accuracy of:  0.542962962962963\n",
            "Norm:  [0.28084642 0.09748831]\n",
            "Epoch:  439  with accuracy of:  0.5457407407407407\n",
            "Norm:  [0.2803539 0.0972799]\n",
            "Epoch:  440  with accuracy of:  0.5472222222222223\n",
            "Norm:  [0.27968876 0.09700175]\n",
            "Epoch:  441  with accuracy of:  0.5494444444444444\n",
            "Norm:  [0.27918244 0.09665893]\n",
            "Epoch:  442  with accuracy of:  0.5527777777777778\n",
            "Norm:  [0.27834629 0.09625917]\n",
            "Epoch:  443  with accuracy of:  0.5538888888888889\n",
            "Norm:  [0.27751729 0.0958096 ]\n",
            "Epoch:  444  with accuracy of:  0.555\n",
            "Norm:  [0.27652468 0.09531827]\n",
            "Epoch:  445  with accuracy of:  0.5553703703703704\n",
            "Norm:  [0.27543837 0.09479185]\n",
            "Epoch:  446  with accuracy of:  0.5574074074074075\n",
            "Norm:  [0.27393017 0.09423343]\n",
            "Epoch:  447  with accuracy of:  0.5583333333333333\n",
            "Norm:  [0.27257829 0.09365453]\n",
            "Epoch:  448  with accuracy of:  0.5607407407407408\n",
            "Norm:  [0.2712729  0.09306093]\n",
            "Epoch:  449  with accuracy of:  0.5627777777777778\n",
            "Norm:  [0.26974463 0.09245371]\n",
            "Epoch:  450  with accuracy of:  0.5640740740740741\n",
            "Norm:  [0.26806595 0.0918365 ]\n",
            "Epoch:  451  with accuracy of:  0.5653703703703704\n",
            "Norm:  [0.26662664 0.09121644]\n",
            "Epoch:  452  with accuracy of:  0.5668518518518518\n",
            "Norm:  [0.2651758  0.09059497]\n",
            "Epoch:  453  with accuracy of:  0.5685185185185185\n",
            "Norm:  [0.26363634 0.08997587]\n",
            "Epoch:  454  with accuracy of:  0.5698148148148148\n",
            "Norm:  [0.26205779 0.08935947]\n",
            "Epoch:  455  with accuracy of:  0.570925925925926\n",
            "Norm:  [0.26043738 0.08874624]\n",
            "Epoch:  456  with accuracy of:  0.5727777777777778\n",
            "Norm:  [0.2586635  0.08813848]\n",
            "Epoch:  457  with accuracy of:  0.5735185185185185\n",
            "Norm:  [0.25710318 0.08753794]\n",
            "Epoch:  458  with accuracy of:  0.575\n",
            "Norm:  [0.25537879 0.08694478]\n",
            "Epoch:  459  with accuracy of:  0.5766666666666667\n",
            "Norm:  [0.2537607  0.08636023]\n",
            "Epoch:  460  with accuracy of:  0.5777777777777777\n",
            "Norm:  [0.25197269 0.08578513]\n",
            "Epoch:  461  with accuracy of:  0.5787037037037037\n",
            "Norm:  [0.25036203 0.08521954]\n",
            "Epoch:  462  with accuracy of:  0.5803703703703704\n",
            "Norm:  [0.24864428 0.08466298]\n",
            "Epoch:  463  with accuracy of:  0.5807407407407408\n",
            "Norm:  [0.24695348 0.08411615]\n",
            "Epoch:  464  with accuracy of:  0.5814814814814815\n",
            "Norm:  [0.24542301 0.08357921]\n",
            "Epoch:  465  with accuracy of:  0.5824074074074074\n",
            "Norm:  [0.24386167 0.08305049]\n",
            "Epoch:  466  with accuracy of:  0.582962962962963\n",
            "Norm:  [0.24234435 0.08253161]\n",
            "Epoch:  467  with accuracy of:  0.5837037037037037\n",
            "Norm:  [0.24077782 0.08202168]\n",
            "Epoch:  468  with accuracy of:  0.5842592592592593\n",
            "Norm:  [0.23922443 0.08152018]\n",
            "Epoch:  469  with accuracy of:  0.5857407407407408\n",
            "Norm:  [0.23764817 0.08102911]\n",
            "Epoch:  470  with accuracy of:  0.5874074074074074\n",
            "Norm:  [0.23615257 0.08054561]\n",
            "Epoch:  471  with accuracy of:  0.5875925925925926\n",
            "Norm:  [0.23459303 0.08006997]\n",
            "Epoch:  472  with accuracy of:  0.5888888888888889\n",
            "Norm:  [0.23291794 0.07960032]\n",
            "Epoch:  473  with accuracy of:  0.5907407407407408\n",
            "Norm:  [0.23150373 0.07913853]\n",
            "Epoch:  474  with accuracy of:  0.5911111111111111\n",
            "Norm:  [0.23016069 0.07868548]\n",
            "Epoch:  475  with accuracy of:  0.5918518518518519\n",
            "Norm:  [0.22863493 0.0782404 ]\n",
            "Epoch:  476  with accuracy of:  0.5929629629629629\n",
            "Norm:  [0.2272416  0.07780093]\n",
            "Epoch:  477  with accuracy of:  0.5940740740740741\n",
            "Norm:  [0.22588445 0.07736809]\n",
            "Epoch:  478  with accuracy of:  0.5944444444444444\n",
            "Norm:  [0.22456572 0.07694182]\n",
            "Epoch:  479  with accuracy of:  0.595\n",
            "Norm:  [0.22320351 0.07652251]\n",
            "Epoch:  480  with accuracy of:  0.5962962962962963\n",
            "Norm:  [0.22174418 0.07611   ]\n",
            "Epoch:  481  with accuracy of:  0.5975925925925926\n",
            "Norm:  [0.22039847 0.07570389]\n",
            "Epoch:  482  with accuracy of:  0.5983333333333334\n",
            "Norm:  [0.21912909 0.07530384]\n",
            "Epoch:  483  with accuracy of:  0.5996296296296296\n",
            "Norm:  [0.21787353 0.07491043]\n",
            "Epoch:  484  with accuracy of:  0.6\n",
            "Norm:  [0.21663776 0.07452214]\n",
            "Epoch:  485  with accuracy of:  0.6005555555555555\n",
            "Norm:  [0.21537734 0.07413882]\n",
            "Epoch:  486  with accuracy of:  0.600925925925926\n",
            "Norm:  [0.21412342 0.07376107]\n",
            "Epoch:  487  with accuracy of:  0.6016666666666667\n",
            "Norm:  [0.21283331 0.07338952]\n",
            "Epoch:  488  with accuracy of:  0.6024074074074074\n",
            "Norm:  [0.21156008 0.07302299]\n",
            "Epoch:  489  with accuracy of:  0.6029629629629629\n",
            "Norm:  [0.21025937 0.07266034]\n",
            "Epoch:  490  with accuracy of:  0.6038888888888889\n",
            "Norm:  [0.20914143 0.07230169]\n",
            "Epoch:  491  with accuracy of:  0.6048148148148148\n",
            "Norm:  [0.20792448 0.07194727]\n",
            "Epoch:  492  with accuracy of:  0.6053703703703703\n",
            "Norm:  [0.20668554 0.07159672]\n",
            "Epoch:  493  with accuracy of:  0.6066666666666667\n",
            "Norm:  [0.20558854 0.07125111]\n",
            "Epoch:  494  with accuracy of:  0.6068518518518519\n",
            "Norm:  [0.20444307 0.07091068]\n",
            "Epoch:  495  with accuracy of:  0.6075925925925926\n",
            "Norm:  [0.20346359 0.07057425]\n",
            "Epoch:  496  with accuracy of:  0.6079629629629629\n",
            "Norm:  [0.20234472 0.07024166]\n",
            "Epoch:  497  with accuracy of:  0.6083333333333333\n",
            "Norm:  [0.20119124 0.06991142]\n",
            "Epoch:  498  with accuracy of:  0.6096296296296296\n",
            "Norm:  [0.20009309 0.06958444]\n",
            "Epoch:  499  with accuracy of:  0.6103703703703703\n",
            "Norm:  [0.19907418 0.06926079]\n",
            "Epoch:  500  with accuracy of:  0.6103703703703703\n",
            "Norm:  [0.19800589 0.06894078]\n",
            "Epoch:  501  with accuracy of:  0.612037037037037\n",
            "Norm:  [0.196942  0.0686249]\n",
            "Epoch:  502  with accuracy of:  0.6124074074074074\n",
            "Norm:  [0.1959071  0.06831348]\n",
            "Epoch:  503  with accuracy of:  0.6129629629629629\n",
            "Norm:  [0.19487649 0.06800615]\n",
            "Epoch:  504  with accuracy of:  0.6137037037037038\n",
            "Norm:  [0.19388007 0.06770242]\n",
            "Epoch:  505  with accuracy of:  0.6148148148148148\n",
            "Norm:  [0.19287266 0.06740163]\n",
            "Epoch:  506  with accuracy of:  0.6157407407407407\n",
            "Norm:  [0.19189349 0.06710386]\n",
            "Epoch:  507  with accuracy of:  0.6162962962962963\n",
            "Norm:  [0.19090274 0.06680859]\n",
            "Epoch:  508  with accuracy of:  0.6174074074074074\n",
            "Norm:  [0.18996727 0.06651666]\n",
            "Epoch:  509  with accuracy of:  0.6179629629629629\n",
            "Norm:  [0.18907577 0.06622746]\n",
            "Epoch:  510  with accuracy of:  0.6185185185185185\n",
            "Norm:  [0.18806009 0.06594194]\n",
            "Epoch:  511  with accuracy of:  0.6194444444444445\n",
            "Norm:  [0.18706659 0.06565939]\n",
            "Epoch:  512  with accuracy of:  0.6192592592592593\n",
            "Norm:  [0.1861633  0.06538028]\n",
            "Epoch:  513  with accuracy of:  0.6192592592592593\n",
            "Norm:  [0.18521715 0.06510422]\n",
            "Epoch:  514  with accuracy of:  0.62\n",
            "Norm:  [0.18441148 0.0648309 ]\n",
            "Epoch:  515  with accuracy of:  0.6209259259259259\n",
            "Norm:  [0.18352066 0.0645599 ]\n",
            "Epoch:  516  with accuracy of:  0.6216666666666667\n",
            "Norm:  [0.18263488 0.06429198]\n",
            "Epoch:  517  with accuracy of:  0.6222222222222222\n",
            "Norm:  [0.18179868 0.06402682]\n",
            "Epoch:  518  with accuracy of:  0.6225925925925926\n",
            "Norm:  [0.1809357  0.06376484]\n",
            "Epoch:  519  with accuracy of:  0.6242592592592593\n",
            "Norm:  [0.18012369 0.06350532]\n",
            "Epoch:  520  with accuracy of:  0.6253703703703704\n",
            "Norm:  [0.17932314 0.06324834]\n",
            "Epoch:  521  with accuracy of:  0.6253703703703704\n",
            "Norm:  [0.1784724  0.06299296]\n",
            "Epoch:  522  with accuracy of:  0.6251851851851852\n",
            "Norm:  [0.17769889 0.06273927]\n",
            "Epoch:  523  with accuracy of:  0.6251851851851852\n",
            "Norm:  [0.17687881 0.0624882 ]\n",
            "Epoch:  524  with accuracy of:  0.6255555555555555\n",
            "Norm:  [0.1759713  0.06223958]\n",
            "Epoch:  525  with accuracy of:  0.6257407407407407\n",
            "Norm:  [0.17509013 0.06199301]\n",
            "Epoch:  526  with accuracy of:  0.6266666666666667\n",
            "Norm:  [0.17427193 0.06174878]\n",
            "Epoch:  527  with accuracy of:  0.6270370370370371\n",
            "Norm:  [0.17353388 0.06150708]\n",
            "Epoch:  528  with accuracy of:  0.6274074074074074\n",
            "Norm:  [0.17268078 0.0612678 ]\n",
            "Epoch:  529  with accuracy of:  0.6277777777777778\n",
            "Norm:  [0.17198633 0.06103001]\n",
            "Epoch:  530  with accuracy of:  0.6281481481481481\n",
            "Norm:  [0.17120502 0.06079438]\n",
            "Epoch:  531  with accuracy of:  0.6285185185185185\n",
            "Norm:  [0.17042571 0.06056049]\n",
            "Epoch:  532  with accuracy of:  0.6285185185185185\n",
            "Norm:  [0.16974671 0.06032832]\n",
            "Epoch:  533  with accuracy of:  0.6287037037037037\n",
            "Norm:  [0.16915566 0.06009828]\n",
            "Epoch:  534  with accuracy of:  0.6290740740740741\n",
            "Norm:  [0.16845165 0.05986953]\n",
            "Epoch:  535  with accuracy of:  0.6292592592592593\n",
            "Norm:  [0.16780404 0.05964332]\n",
            "Epoch:  536  with accuracy of:  0.6294444444444445\n",
            "Norm:  [0.16705824 0.05941901]\n",
            "Epoch:  537  with accuracy of:  0.6301851851851852\n",
            "Norm:  [0.16638237 0.05919621]\n",
            "Epoch:  538  with accuracy of:  0.6309259259259259\n",
            "Norm:  [0.16561013 0.0589748 ]\n",
            "Epoch:  539  with accuracy of:  0.6314814814814815\n",
            "Norm:  [0.16493373 0.05875486]\n",
            "Epoch:  540  with accuracy of:  0.6324074074074074\n",
            "Norm:  [0.16425702 0.05853619]\n",
            "Epoch:  541  with accuracy of:  0.6331481481481481\n",
            "Norm:  [0.16359369 0.05831875]\n",
            "Epoch:  542  with accuracy of:  0.6335185185185185\n",
            "Norm:  [0.1629195  0.05810368]\n",
            "Epoch:  543  with accuracy of:  0.6337037037037037\n",
            "Norm:  [0.16216214 0.05789007]\n",
            "Epoch:  544  with accuracy of:  0.6340740740740741\n",
            "Norm:  [0.16154572 0.0576786 ]\n",
            "Epoch:  545  with accuracy of:  0.6342592592592593\n",
            "Norm:  [0.16086626 0.05746872]\n",
            "Epoch:  546  with accuracy of:  0.6353703703703704\n",
            "Norm:  [0.16032757 0.05726005]\n",
            "Epoch:  547  with accuracy of:  0.6359259259259259\n",
            "Norm:  [0.15962218 0.05705335]\n",
            "Epoch:  548  with accuracy of:  0.6361111111111111\n",
            "Norm:  [0.15903407 0.05684854]\n",
            "Epoch:  549  with accuracy of:  0.6366666666666667\n",
            "Norm:  [0.15840475 0.05664532]\n",
            "Epoch:  550  with accuracy of:  0.6372222222222222\n",
            "Norm:  [0.15779839 0.05644361]\n",
            "Epoch:  551  with accuracy of:  0.6374074074074074\n",
            "Norm:  [0.15715454 0.05624308]\n",
            "Epoch:  552  with accuracy of:  0.6377777777777778\n",
            "Norm:  [0.15649968 0.05604381]\n",
            "Epoch:  553  with accuracy of:  0.637962962962963\n",
            "Norm:  [0.155876   0.05584604]\n",
            "Epoch:  554  with accuracy of:  0.6385185185185185\n",
            "Norm:  [0.15522661 0.05564984]\n",
            "Epoch:  555  with accuracy of:  0.6396296296296297\n",
            "Norm:  [0.1545733  0.05545441]\n",
            "Epoch:  556  with accuracy of:  0.6401851851851852\n",
            "Norm:  [0.15395455 0.05526019]\n",
            "Epoch:  557  with accuracy of:  0.6407407407407407\n",
            "Norm:  [0.15337002 0.05506811]\n",
            "Epoch:  558  with accuracy of:  0.6412962962962963\n",
            "Norm:  [0.15279678 0.05487719]\n",
            "Epoch:  559  with accuracy of:  0.6418518518518519\n",
            "Norm:  [0.15227466 0.05468851]\n",
            "Epoch:  560  with accuracy of:  0.6424074074074074\n",
            "Norm:  [0.15177654 0.05450117]\n",
            "Epoch:  561  with accuracy of:  0.6427777777777778\n",
            "Norm:  [0.15114682 0.05431471]\n",
            "Epoch:  562  with accuracy of:  0.6431481481481481\n",
            "Norm:  [0.15051165 0.05412956]\n",
            "Epoch:  563  with accuracy of:  0.6431481481481481\n",
            "Norm:  [0.1500307  0.05394552]\n",
            "Epoch:  564  with accuracy of:  0.6438888888888888\n",
            "Norm:  [0.14936646 0.05376258]\n",
            "Epoch:  565  with accuracy of:  0.6446296296296297\n",
            "Norm:  [0.14877724 0.05358153]\n",
            "Epoch:  566  with accuracy of:  0.645\n",
            "Norm:  [0.14817479 0.05340182]\n",
            "Epoch:  567  with accuracy of:  0.6453703703703704\n",
            "Norm:  [0.14765124 0.05322369]\n",
            "Epoch:  568  with accuracy of:  0.6457407407407407\n",
            "Norm:  [0.14713797 0.05304684]\n",
            "Epoch:  569  with accuracy of:  0.6461111111111111\n",
            "Norm:  [0.14659526 0.05287153]\n",
            "Epoch:  570  with accuracy of:  0.6464814814814814\n",
            "Norm:  [0.14611539 0.05269738]\n",
            "Epoch:  571  with accuracy of:  0.6468518518518519\n",
            "Norm:  [0.14564798 0.05252501]\n",
            "Epoch:  572  with accuracy of:  0.6468518518518519\n",
            "Norm:  [0.14514332 0.05235389]\n",
            "Epoch:  573  with accuracy of:  0.6475925925925926\n",
            "Norm:  [0.14464959 0.05218427]\n",
            "Epoch:  574  with accuracy of:  0.6481481481481481\n",
            "Norm:  [0.14419588 0.05201593]\n",
            "Epoch:  575  with accuracy of:  0.6485185185185185\n",
            "Norm:  [0.14370127 0.05184921]\n",
            "Epoch:  576  with accuracy of:  0.6485185185185185\n",
            "Norm:  [0.14320403 0.05168392]\n",
            "Epoch:  577  with accuracy of:  0.6488888888888888\n",
            "Norm:  [0.14273686 0.05152   ]\n",
            "Epoch:  578  with accuracy of:  0.6494444444444445\n",
            "Norm:  [0.14227885 0.0513571 ]\n",
            "Epoch:  579  with accuracy of:  0.6496296296296297\n",
            "Norm:  [0.14180601 0.05119495]\n",
            "Epoch:  580  with accuracy of:  0.65\n",
            "Norm:  [0.14138149 0.05103414]\n",
            "Epoch:  581  with accuracy of:  0.6503703703703704\n",
            "Norm:  [0.14094736 0.05087441]\n",
            "Epoch:  582  with accuracy of:  0.6505555555555556\n",
            "Norm:  [0.14052791 0.05071527]\n",
            "Epoch:  583  with accuracy of:  0.6509259259259259\n",
            "Norm:  [0.14011271 0.05055711]\n",
            "Epoch:  584  with accuracy of:  0.6511111111111111\n",
            "Norm:  [0.13969186 0.05040017]\n",
            "Epoch:  585  with accuracy of:  0.6511111111111111\n",
            "Norm:  [0.13921354 0.05024414]\n",
            "Epoch:  586  with accuracy of:  0.6512962962962963\n",
            "Norm:  [0.13880325 0.05008937]\n",
            "Epoch:  587  with accuracy of:  0.6518518518518519\n",
            "Norm:  [0.138333   0.04993561]\n",
            "Epoch:  588  with accuracy of:  0.6524074074074074\n",
            "Norm:  [0.13787809 0.0497829 ]\n",
            "Epoch:  589  with accuracy of:  0.6531481481481481\n",
            "Norm:  [0.13741566 0.04963097]\n",
            "Epoch:  590  with accuracy of:  0.6535185185185185\n",
            "Norm:  [0.13699037 0.04948032]\n",
            "Epoch:  591  with accuracy of:  0.6542592592592592\n",
            "Norm:  [0.13661807 0.04933082]\n",
            "Epoch:  592  with accuracy of:  0.6548148148148148\n",
            "Norm:  [0.13625125 0.04918224]\n",
            "Epoch:  593  with accuracy of:  0.6548148148148148\n",
            "Norm:  [0.13588953 0.04903502]\n",
            "Epoch:  594  with accuracy of:  0.6548148148148148\n",
            "Norm:  [0.13551284 0.04888894]\n",
            "Epoch:  595  with accuracy of:  0.6546296296296297\n",
            "Norm:  [0.13506664 0.04874373]\n",
            "Epoch:  596  with accuracy of:  0.6546296296296297\n",
            "Norm:  [0.13466666 0.04859923]\n",
            "Epoch:  597  with accuracy of:  0.6551851851851852\n",
            "Norm:  [0.13427375 0.04845533]\n",
            "Epoch:  598  with accuracy of:  0.6551851851851852\n",
            "Norm:  [0.13386595 0.04831272]\n",
            "Epoch:  599  with accuracy of:  0.6553703703703704\n",
            "Norm:  [0.13341036 0.04817079]\n",
            "Epoch:  600  with accuracy of:  0.6561111111111111\n",
            "Norm:  [0.13303552 0.04802901]\n",
            "Epoch:  601  with accuracy of:  0.6562962962962963\n",
            "Norm:  [0.13259237 0.04788868]\n",
            "Epoch:  602  with accuracy of:  0.6566666666666666\n",
            "Norm:  [0.13218994 0.04774937]\n",
            "Epoch:  603  with accuracy of:  0.6570370370370371\n",
            "Norm:  [0.13188994 0.0476113 ]\n",
            "Epoch:  604  with accuracy of:  0.6575925925925926\n",
            "Norm:  [0.13153587 0.04747456]\n",
            "Epoch:  605  with accuracy of:  0.6577777777777778\n",
            "Norm:  [0.1311154  0.04733866]\n",
            "Epoch:  606  with accuracy of:  0.6581481481481481\n",
            "Norm:  [0.13074885 0.04720408]\n",
            "Epoch:  607  with accuracy of:  0.6583333333333333\n",
            "Norm:  [0.13041385 0.04707084]\n",
            "Epoch:  608  with accuracy of:  0.6583333333333333\n",
            "Norm:  [0.13004527 0.04693805]\n",
            "Epoch:  609  with accuracy of:  0.6583333333333333\n",
            "Norm:  [0.12966383 0.04680612]\n",
            "Epoch:  610  with accuracy of:  0.6587037037037037\n",
            "Norm:  [0.12931054 0.04667481]\n",
            "Epoch:  611  with accuracy of:  0.6588888888888889\n",
            "Norm:  [0.12893925 0.04654457]\n",
            "Epoch:  612  with accuracy of:  0.6588888888888889\n",
            "Norm:  [0.12858104 0.04641424]\n",
            "Epoch:  613  with accuracy of:  0.659074074074074\n",
            "Norm:  [0.12824594 0.04628498]\n",
            "Epoch:  614  with accuracy of:  0.6592592592592592\n",
            "Norm:  [0.12794591 0.04615646]\n",
            "Epoch:  615  with accuracy of:  0.6594444444444445\n",
            "Norm:  [0.12765088 0.04602924]\n",
            "Epoch:  616  with accuracy of:  0.6598148148148149\n",
            "Norm:  [0.12727792 0.04590255]\n",
            "Epoch:  617  with accuracy of:  0.6601851851851852\n",
            "Norm:  [0.12688951 0.04577695]\n",
            "Epoch:  618  with accuracy of:  0.6601851851851852\n",
            "Norm:  [0.12653763 0.04565216]\n",
            "Epoch:  619  with accuracy of:  0.6603703703703704\n",
            "Norm:  [0.12617113 0.04552814]\n",
            "Epoch:  620  with accuracy of:  0.6609259259259259\n",
            "Norm:  [0.12580998 0.04540493]\n",
            "Epoch:  621  with accuracy of:  0.6611111111111111\n",
            "Norm:  [0.12550469 0.04528236]\n",
            "Epoch:  622  with accuracy of:  0.6618518518518518\n",
            "Norm:  [0.12512573 0.04515945]\n",
            "Epoch:  623  with accuracy of:  0.6620370370370371\n",
            "Norm:  [0.12476622 0.04503718]\n",
            "Epoch:  624  with accuracy of:  0.6618518518518518\n",
            "Norm:  [0.12435127 0.0449161 ]\n",
            "Epoch:  625  with accuracy of:  0.6620370370370371\n",
            "Norm:  [0.12397456 0.04479545]\n",
            "Epoch:  626  with accuracy of:  0.6620370370370371\n",
            "Norm:  [0.12369214 0.0446756 ]\n",
            "Epoch:  627  with accuracy of:  0.6625925925925926\n",
            "Norm:  [0.12339877 0.04455676]\n",
            "Epoch:  628  with accuracy of:  0.6627777777777778\n",
            "Norm:  [0.12308512 0.04443811]\n",
            "Epoch:  629  with accuracy of:  0.662962962962963\n",
            "Norm:  [0.12278193 0.04432039]\n",
            "Epoch:  630  with accuracy of:  0.6631481481481482\n",
            "Norm:  [0.12245552 0.04420325]\n",
            "Epoch:  631  with accuracy of:  0.6633333333333333\n",
            "Norm:  [0.1220871  0.04408656]\n",
            "Epoch:  632  with accuracy of:  0.6635185185185185\n",
            "Norm:  [0.12176361 0.04397014]\n",
            "Epoch:  633  with accuracy of:  0.6642592592592592\n",
            "Norm:  [0.12137645 0.04385502]\n",
            "Epoch:  634  with accuracy of:  0.665\n",
            "Norm:  [0.12113407 0.04374074]\n",
            "Epoch:  635  with accuracy of:  0.6655555555555556\n",
            "Norm:  [0.12076611 0.04362728]\n",
            "Epoch:  636  with accuracy of:  0.6655555555555556\n",
            "Norm:  [0.12046206 0.0435143 ]\n",
            "Epoch:  637  with accuracy of:  0.6659259259259259\n",
            "Norm:  [0.12025196 0.04340197]\n",
            "Epoch:  638  with accuracy of:  0.6668518518518518\n",
            "Norm:  [0.11999261 0.04328983]\n",
            "Epoch:  639  with accuracy of:  0.667037037037037\n",
            "Norm:  [0.11971766 0.04317791]\n",
            "Epoch:  640  with accuracy of:  0.6675925925925926\n",
            "Norm:  [0.11938476 0.04306767]\n",
            "Epoch:  641  with accuracy of:  0.667962962962963\n",
            "Norm:  [0.11911042 0.04295837]\n",
            "Epoch:  642  with accuracy of:  0.667962962962963\n",
            "Norm:  [0.11879491 0.04284977]\n",
            "Epoch:  643  with accuracy of:  0.6681481481481482\n",
            "Norm:  [0.11844882 0.04274221]\n",
            "Epoch:  644  with accuracy of:  0.6683333333333333\n",
            "Norm:  [0.11807937 0.04263546]\n",
            "Epoch:  645  with accuracy of:  0.6685185185185185\n",
            "Norm:  [0.11774339 0.04252894]\n",
            "Epoch:  646  with accuracy of:  0.6687037037037037\n",
            "Norm:  [0.11742245 0.04242299]\n",
            "Epoch:  647  with accuracy of:  0.6688888888888889\n",
            "Norm:  [0.11710546 0.04231724]\n",
            "Epoch:  648  with accuracy of:  0.6687037037037037\n",
            "Norm:  [0.1168517  0.04221191]\n",
            "Epoch:  649  with accuracy of:  0.669074074074074\n",
            "Norm:  [0.11657392 0.04210741]\n",
            "Epoch:  650  with accuracy of:  0.6688888888888889\n",
            "Norm:  [0.11630982 0.04200317]\n",
            "Epoch:  651  with accuracy of:  0.669074074074074\n",
            "Norm:  [0.11599587 0.04189965]\n",
            "Epoch:  652  with accuracy of:  0.6692592592592592\n",
            "Norm:  [0.11570964 0.04179661]\n",
            "Epoch:  653  with accuracy of:  0.6692592592592592\n",
            "Norm:  [0.11544431 0.04169387]\n",
            "Epoch:  654  with accuracy of:  0.6692592592592592\n",
            "Norm:  [0.11513962 0.04159185]\n",
            "Epoch:  655  with accuracy of:  0.6694444444444444\n",
            "Norm:  [0.11483047 0.0414907 ]\n",
            "Epoch:  656  with accuracy of:  0.6696296296296296\n",
            "Norm:  [0.11451195 0.04139039]\n",
            "Epoch:  657  with accuracy of:  0.6701851851851852\n",
            "Norm:  [0.1143267 0.041291 ]\n",
            "Epoch:  658  with accuracy of:  0.6707407407407407\n",
            "Norm:  [0.11401055 0.04119206]\n",
            "Epoch:  659  with accuracy of:  0.6711111111111111\n",
            "Norm:  [0.11374995 0.04109401]\n",
            "Epoch:  660  with accuracy of:  0.6711111111111111\n",
            "Norm:  [0.11348551 0.04099668]\n",
            "Epoch:  661  with accuracy of:  0.6716666666666666\n",
            "Norm:  [0.11328865 0.04089953]\n",
            "Epoch:  662  with accuracy of:  0.6716666666666666\n",
            "Norm:  [0.11306551 0.04080245]\n",
            "Epoch:  663  with accuracy of:  0.672037037037037\n",
            "Norm:  [0.1128451  0.04070656]\n",
            "Epoch:  664  with accuracy of:  0.6722222222222223\n",
            "Norm:  [0.11259721 0.04061111]\n",
            "Epoch:  665  with accuracy of:  0.6724074074074075\n",
            "Norm:  [0.11229844 0.04051599]\n",
            "Epoch:  666  with accuracy of:  0.6727777777777778\n",
            "Norm:  [0.11202386 0.04042145]\n",
            "Epoch:  667  with accuracy of:  0.6727777777777778\n",
            "Norm:  [0.11176526 0.04032797]\n",
            "Epoch:  668  with accuracy of:  0.6727777777777778\n",
            "Norm:  [0.11150639 0.04023458]\n",
            "Epoch:  669  with accuracy of:  0.6731481481481482\n",
            "Norm:  [0.11124932 0.04014121]\n",
            "Epoch:  670  with accuracy of:  0.6733333333333333\n",
            "Norm:  [0.11103599 0.04004828]\n",
            "Epoch:  671  with accuracy of:  0.6733333333333333\n",
            "Norm:  [0.11076848 0.03995553]\n",
            "Epoch:  672  with accuracy of:  0.6733333333333333\n",
            "Norm:  [0.11052037 0.03986286]\n",
            "Epoch:  673  with accuracy of:  0.6737037037037037\n",
            "Norm:  [0.11028465 0.03977074]\n",
            "Epoch:  674  with accuracy of:  0.6738888888888889\n",
            "Norm:  [0.11005668 0.03967872]\n",
            "Epoch:  675  with accuracy of:  0.674074074074074\n",
            "Norm:  [0.10976427 0.03958724]\n",
            "Epoch:  676  with accuracy of:  0.6742592592592592\n",
            "Norm:  [0.10953728 0.03949672]\n",
            "Epoch:  677  with accuracy of:  0.6742592592592592\n",
            "Norm:  [0.10932055 0.03940682]\n",
            "Epoch:  678  with accuracy of:  0.6744444444444444\n",
            "Norm:  [0.1089768  0.03931682]\n",
            "Epoch:  679  with accuracy of:  0.6751851851851852\n",
            "Norm:  [0.10873958 0.03922776]\n",
            "Epoch:  680  with accuracy of:  0.6753703703703704\n",
            "Norm:  [0.10849151 0.03913964]\n",
            "Epoch:  681  with accuracy of:  0.6757407407407408\n",
            "Norm:  [0.10828055 0.03905197]\n",
            "Epoch:  682  with accuracy of:  0.6759259259259259\n",
            "Norm:  [0.10804967 0.03896485]\n",
            "Epoch:  683  with accuracy of:  0.6761111111111111\n",
            "Norm:  [0.10784538 0.03887836]\n",
            "Epoch:  684  with accuracy of:  0.6762962962962963\n",
            "Norm:  [0.10766016 0.03879237]\n",
            "Epoch:  685  with accuracy of:  0.6766666666666666\n",
            "Norm:  [0.10740643 0.03870686]\n",
            "Epoch:  686  with accuracy of:  0.6766666666666666\n",
            "Norm:  [0.10722908 0.03862205]\n",
            "Epoch:  687  with accuracy of:  0.6768518518518518\n",
            "Norm:  [0.10698939 0.03853791]\n",
            "Epoch:  688  with accuracy of:  0.6766666666666666\n",
            "Norm:  [0.10682957 0.03845377]\n",
            "Epoch:  689  with accuracy of:  0.6766666666666666\n",
            "Norm:  [0.10662228 0.03836963]\n",
            "Epoch:  690  with accuracy of:  0.6768518518518518\n",
            "Norm:  [0.1063962  0.03828617]\n",
            "Epoch:  691  with accuracy of:  0.677037037037037\n",
            "Norm:  [0.10620326 0.03820333]\n",
            "Epoch:  692  with accuracy of:  0.6772222222222222\n",
            "Norm:  [0.10602838 0.03812077]\n",
            "Epoch:  693  with accuracy of:  0.6774074074074075\n",
            "Norm:  [0.10576645 0.03803858]\n",
            "Epoch:  694  with accuracy of:  0.6775925925925926\n",
            "Norm:  [0.10555179 0.03795665]\n",
            "Epoch:  695  with accuracy of:  0.6777777777777778\n",
            "Norm:  [0.10525222 0.03787508]\n",
            "Epoch:  696  with accuracy of:  0.6781481481481482\n",
            "Norm:  [0.10508215 0.03779387]\n",
            "Epoch:  697  with accuracy of:  0.6781481481481482\n",
            "Norm:  [0.10488775 0.03771306]\n",
            "Epoch:  698  with accuracy of:  0.6781481481481482\n",
            "Norm:  [0.10462808 0.03763285]\n",
            "Epoch:  699  with accuracy of:  0.6781481481481482\n",
            "Norm:  [0.10440601 0.03755252]\n",
            "Epoch:  700  with accuracy of:  0.6781481481481482\n",
            "Norm:  [0.10419596 0.03747298]\n",
            "Epoch:  701  with accuracy of:  0.677962962962963\n",
            "Norm:  [0.10395736 0.03739427]\n",
            "Epoch:  702  with accuracy of:  0.6781481481481482\n",
            "Norm:  [0.10375977 0.03731597]\n",
            "Epoch:  703  with accuracy of:  0.6783333333333333\n",
            "Norm:  [0.1035432  0.03723806]\n",
            "Epoch:  704  with accuracy of:  0.6787037037037037\n",
            "Norm:  [0.1033729  0.03716056]\n",
            "Epoch:  705  with accuracy of:  0.6787037037037037\n",
            "Norm:  [0.10317893 0.03708354]\n",
            "Epoch:  706  with accuracy of:  0.6788888888888889\n",
            "Norm:  [0.10296548 0.03700682]\n",
            "Epoch:  707  with accuracy of:  0.6788888888888889\n",
            "Norm:  [0.10273796 0.0369306 ]\n",
            "Epoch:  708  with accuracy of:  0.6794444444444444\n",
            "Norm:  [0.10254944 0.03685448]\n",
            "Epoch:  709  with accuracy of:  0.6792592592592592\n",
            "Norm:  [0.10231871 0.03677906]\n",
            "Epoch:  710  with accuracy of:  0.6792592592592592\n",
            "Norm:  [0.10215646 0.03670415]\n",
            "Epoch:  711  with accuracy of:  0.6796296296296296\n",
            "Norm:  [0.1019485  0.03662957]\n",
            "Epoch:  712  with accuracy of:  0.6796296296296296\n",
            "Norm:  [0.10175911 0.03655567]\n",
            "Epoch:  713  with accuracy of:  0.6796296296296296\n",
            "Norm:  [0.10160524 0.0364815 ]\n",
            "Epoch:  714  with accuracy of:  0.6798148148148148\n",
            "Norm:  [0.10136853 0.03640793]\n",
            "Epoch:  715  with accuracy of:  0.6798148148148148\n",
            "Norm:  [0.10118303 0.03633499]\n",
            "Epoch:  716  with accuracy of:  0.68\n",
            "Norm:  [0.10098853 0.03626222]\n",
            "Epoch:  717  with accuracy of:  0.6801851851851852\n",
            "Norm:  [0.10076161 0.0361899 ]\n",
            "Epoch:  718  with accuracy of:  0.6803703703703704\n",
            "Norm:  [0.10056343 0.03611794]\n",
            "Epoch:  719  with accuracy of:  0.6803703703703704\n",
            "Norm:  [0.10037036 0.03604661]\n",
            "Epoch:  720  with accuracy of:  0.6805555555555556\n",
            "Norm:  [0.10019761 0.0359755 ]\n",
            "Epoch:  721  with accuracy of:  0.6805555555555556\n",
            "Norm:  [0.10001931 0.03590432]\n",
            "Epoch:  722  with accuracy of:  0.6807407407407408\n",
            "Norm:  [0.09983063 0.03583382]\n",
            "Epoch:  723  with accuracy of:  0.6807407407407408\n",
            "Norm:  [0.09964376 0.03576381]\n",
            "Epoch:  724  with accuracy of:  0.6811111111111111\n",
            "Norm:  [0.0994372 0.0356942]\n",
            "Epoch:  725  with accuracy of:  0.6812962962962963\n",
            "Norm:  [0.09929129 0.03562474]\n",
            "Epoch:  726  with accuracy of:  0.6816666666666666\n",
            "Norm:  [0.09919047 0.03555572]\n",
            "Epoch:  727  with accuracy of:  0.6818518518518518\n",
            "Norm:  [0.09906191 0.03548694]\n",
            "Epoch:  728  with accuracy of:  0.6816666666666666\n",
            "Norm:  [0.09890691 0.03541779]\n",
            "Epoch:  729  with accuracy of:  0.6816666666666666\n",
            "Norm:  [0.0987812  0.03534915]\n",
            "Epoch:  730  with accuracy of:  0.6814814814814815\n",
            "Norm:  [0.09860232 0.03528108]\n",
            "Epoch:  731  with accuracy of:  0.6816666666666666\n",
            "Norm:  [0.09842459 0.0352133 ]\n",
            "Epoch:  732  with accuracy of:  0.6818518518518518\n",
            "Norm:  [0.09822424 0.03514587]\n",
            "Epoch:  733  with accuracy of:  0.682037037037037\n",
            "Norm:  [0.09808551 0.03507869]\n",
            "Epoch:  734  with accuracy of:  0.682037037037037\n",
            "Norm:  [0.09790817 0.03501215]\n",
            "Epoch:  735  with accuracy of:  0.682037037037037\n",
            "Norm:  [0.09780727 0.0349463 ]\n",
            "Epoch:  736  with accuracy of:  0.682037037037037\n",
            "Norm:  [0.09762859 0.03488144]\n",
            "Epoch:  737  with accuracy of:  0.682037037037037\n",
            "Norm:  [0.09744135 0.03481672]\n",
            "Epoch:  738  with accuracy of:  0.6825925925925926\n",
            "Norm:  [0.09726026 0.03475239]\n",
            "Epoch:  739  with accuracy of:  0.6824074074074075\n",
            "Norm:  [0.09702434 0.03468848]\n",
            "Epoch:  740  with accuracy of:  0.6825925925925926\n",
            "Norm:  [0.09688784 0.03462452]\n",
            "Epoch:  741  with accuracy of:  0.6825925925925926\n",
            "Norm:  [0.09671472 0.0345606 ]\n",
            "Epoch:  742  with accuracy of:  0.6827777777777778\n",
            "Norm:  [0.09656412 0.03449716]\n",
            "Epoch:  743  with accuracy of:  0.682962962962963\n",
            "Norm:  [0.0964074  0.03443405]\n",
            "Epoch:  744  with accuracy of:  0.682962962962963\n",
            "Norm:  [0.09627672 0.03437128]\n",
            "Epoch:  745  with accuracy of:  0.6835185185185185\n",
            "Norm:  [0.09616582 0.0343093 ]\n",
            "Epoch:  746  with accuracy of:  0.6835185185185185\n",
            "Norm:  [0.09600733 0.03424797]\n",
            "Epoch:  747  with accuracy of:  0.6835185185185185\n",
            "Norm:  [0.09582271 0.03418709]\n",
            "Epoch:  748  with accuracy of:  0.6835185185185185\n",
            "Norm:  [0.09565553 0.03412627]\n",
            "Epoch:  749  with accuracy of:  0.6837037037037037\n",
            "Norm:  [0.09548321 0.03406542]\n",
            "Epoch:  750  with accuracy of:  0.6838888888888889\n",
            "Norm:  [0.09531648 0.03400484]\n",
            "Epoch:  751  with accuracy of:  0.6840740740740741\n",
            "Norm:  [0.09513244 0.03394445]\n",
            "Epoch:  752  with accuracy of:  0.6840740740740741\n",
            "Norm:  [0.09494985 0.03388451]\n",
            "Epoch:  753  with accuracy of:  0.6838888888888889\n",
            "Norm:  [0.09477888 0.03382472]\n",
            "Epoch:  754  with accuracy of:  0.6838888888888889\n",
            "Norm:  [0.09465047 0.03376496]\n",
            "Epoch:  755  with accuracy of:  0.6842592592592592\n",
            "Norm:  [0.09448591 0.03370537]\n",
            "Epoch:  756  with accuracy of:  0.6840740740740741\n",
            "Norm:  [0.0943789  0.03364603]\n",
            "Epoch:  757  with accuracy of:  0.6842592592592592\n",
            "Norm:  [0.0942424  0.03358714]\n",
            "Epoch:  758  with accuracy of:  0.6846296296296296\n",
            "Norm:  [0.09412156 0.03352877]\n",
            "Epoch:  759  with accuracy of:  0.6846296296296296\n",
            "Norm:  [0.09399217 0.03347091]\n",
            "Epoch:  760  with accuracy of:  0.6846296296296296\n",
            "Norm:  [0.09386274 0.0334136 ]\n",
            "Epoch:  761  with accuracy of:  0.6846296296296296\n",
            "Norm:  [0.09374361 0.03335664]\n",
            "Epoch:  762  with accuracy of:  0.6846296296296296\n",
            "Norm:  [0.0936172 0.0332999]\n",
            "Epoch:  763  with accuracy of:  0.6844444444444444\n",
            "Norm:  [0.09347615 0.03324332]\n",
            "Epoch:  764  with accuracy of:  0.6842592592592592\n",
            "Norm:  [0.09337055 0.03318711]\n",
            "Epoch:  765  with accuracy of:  0.6844444444444444\n",
            "Norm:  [0.09318359 0.03313104]\n",
            "Epoch:  766  with accuracy of:  0.6844444444444444\n",
            "Norm:  [0.09302913 0.03307558]\n",
            "Epoch:  767  with accuracy of:  0.6846296296296296\n",
            "Norm:  [0.09292542 0.03301996]\n",
            "Epoch:  768  with accuracy of:  0.6846296296296296\n",
            "Norm:  [0.09274239 0.0329647 ]\n",
            "Epoch:  769  with accuracy of:  0.6848148148148148\n",
            "Norm:  [0.09267502 0.03290956]\n",
            "Epoch:  770  with accuracy of:  0.6855555555555556\n",
            "Norm:  [0.09255308 0.03285465]\n",
            "Epoch:  771  with accuracy of:  0.6853703703703704\n",
            "Norm:  [0.09240416 0.0328    ]\n",
            "Epoch:  772  with accuracy of:  0.6853703703703704\n",
            "Norm:  [0.09229126 0.03274544]\n",
            "Epoch:  773  with accuracy of:  0.6857407407407408\n",
            "Norm:  [0.09218359 0.03269088]\n",
            "Epoch:  774  with accuracy of:  0.6857407407407408\n",
            "Norm:  [0.09204672 0.03263673]\n",
            "Epoch:  775  with accuracy of:  0.6859259259259259\n",
            "Norm:  [0.09181456 0.03258302]\n",
            "Epoch:  776  with accuracy of:  0.6859259259259259\n",
            "Norm:  [0.09163285 0.03252948]\n",
            "Epoch:  777  with accuracy of:  0.6861111111111111\n",
            "Norm:  [0.09145647 0.03247588]\n",
            "Epoch:  778  with accuracy of:  0.6861111111111111\n",
            "Norm:  [0.09133077 0.03242206]\n",
            "Epoch:  779  with accuracy of:  0.6866666666666666\n",
            "Norm:  [0.0912098  0.03236833]\n",
            "Epoch:  780  with accuracy of:  0.6866666666666666\n",
            "Norm:  [0.09105473 0.03231418]\n",
            "Epoch:  781  with accuracy of:  0.6868518518518518\n",
            "Norm:  [0.09096264 0.03226021]\n",
            "Epoch:  782  with accuracy of:  0.6864814814814815\n",
            "Norm:  [0.09088289 0.03220629]\n",
            "Epoch:  783  with accuracy of:  0.6866666666666666\n",
            "Norm:  [0.09071742 0.03215286]\n",
            "Epoch:  784  with accuracy of:  0.6866666666666666\n",
            "Norm:  [0.09063057 0.0320996 ]\n",
            "Epoch:  785  with accuracy of:  0.6872222222222222\n",
            "Norm:  [0.09052819 0.03204633]\n",
            "Epoch:  786  with accuracy of:  0.687037037037037\n",
            "Norm:  [0.09038873 0.03199347]\n",
            "Epoch:  787  with accuracy of:  0.687037037037037\n",
            "Norm:  [0.09023802 0.03194118]\n",
            "Epoch:  788  with accuracy of:  0.6872222222222222\n",
            "Norm:  [0.09015165 0.03188925]\n",
            "Epoch:  789  with accuracy of:  0.6874074074074074\n",
            "Norm:  [0.090059   0.03183743]\n",
            "Epoch:  790  with accuracy of:  0.6875925925925926\n",
            "Norm:  [0.08990616 0.03178604]\n",
            "Epoch:  791  with accuracy of:  0.6874074074074074\n",
            "Norm:  [0.08972293 0.03173499]\n",
            "Epoch:  792  with accuracy of:  0.6875925925925926\n",
            "Norm:  [0.08959799 0.03168437]\n",
            "Epoch:  793  with accuracy of:  0.6875925925925926\n",
            "Norm:  [0.0894892  0.03163387]\n",
            "Epoch:  794  with accuracy of:  0.6875925925925926\n",
            "Norm:  [0.08932802 0.03158362]\n",
            "Epoch:  795  with accuracy of:  0.687962962962963\n",
            "Norm:  [0.08918201 0.03153343]\n",
            "Epoch:  796  with accuracy of:  0.687962962962963\n",
            "Norm:  [0.08897847 0.03148355]\n",
            "Epoch:  797  with accuracy of:  0.687962962962963\n",
            "Norm:  [0.08894675 0.03143342]\n",
            "Epoch:  798  with accuracy of:  0.687962962962963\n",
            "Norm:  [0.08885696 0.03138393]\n",
            "Epoch:  799  with accuracy of:  0.687962962962963\n",
            "Norm:  [0.08868975 0.03133496]\n",
            "Epoch:  800  with accuracy of:  0.687962962962963\n",
            "Norm:  [0.08853846 0.03128622]\n",
            "Epoch:  801  with accuracy of:  0.6883333333333334\n",
            "Norm:  [0.08838342 0.03123761]\n",
            "Epoch:  802  with accuracy of:  0.6883333333333334\n",
            "Norm:  [0.08828356 0.0311893 ]\n",
            "Epoch:  803  with accuracy of:  0.6883333333333334\n",
            "Norm:  [0.08816247 0.03114139]\n",
            "Epoch:  804  with accuracy of:  0.6885185185185185\n",
            "Norm:  [0.08807172 0.03109351]\n",
            "Epoch:  805  with accuracy of:  0.6885185185185185\n",
            "Norm:  [0.08791901 0.03104566]\n",
            "Epoch:  806  with accuracy of:  0.6885185185185185\n",
            "Norm:  [0.08780004 0.03099808]\n",
            "Epoch:  807  with accuracy of:  0.6888888888888889\n",
            "Norm:  [0.0876299  0.03095084]\n",
            "Epoch:  808  with accuracy of:  0.6890740740740741\n",
            "Norm:  [0.08751863 0.03090363]\n",
            "Epoch:  809  with accuracy of:  0.6890740740740741\n",
            "Norm:  [0.08741154 0.03085667]\n",
            "Epoch:  810  with accuracy of:  0.6890740740740741\n",
            "Norm:  [0.08728765 0.03080978]\n",
            "Epoch:  811  with accuracy of:  0.6890740740740741\n",
            "Norm:  [0.08715981 0.03076299]\n",
            "Epoch:  812  with accuracy of:  0.6894444444444444\n",
            "Norm:  [0.08706087 0.03071582]\n",
            "Epoch:  813  with accuracy of:  0.6894444444444444\n",
            "Norm:  [0.08698401 0.03066909]\n",
            "Epoch:  814  with accuracy of:  0.6896296296296296\n",
            "Norm:  [0.08686647 0.03062258]\n",
            "Epoch:  815  with accuracy of:  0.6898148148148148\n",
            "Norm:  [0.08672157 0.03057639]\n",
            "Epoch:  816  with accuracy of:  0.6901851851851852\n",
            "Norm:  [0.08658715 0.03053038]\n",
            "Epoch:  817  with accuracy of:  0.6905555555555556\n",
            "Norm:  [0.08640163 0.03048473]\n",
            "Epoch:  818  with accuracy of:  0.6905555555555556\n",
            "Norm:  [0.08631375 0.03043936]\n",
            "Epoch:  819  with accuracy of:  0.6907407407407408\n",
            "Norm:  [0.08618528 0.03039436]\n",
            "Epoch:  820  with accuracy of:  0.6907407407407408\n",
            "Norm:  [0.08606089 0.03034946]\n",
            "Epoch:  821  with accuracy of:  0.6909259259259259\n",
            "Norm:  [0.08602176 0.03030507]\n",
            "Epoch:  822  with accuracy of:  0.6911111111111111\n",
            "Norm:  [0.08588904 0.03026049]\n",
            "Epoch:  823  with accuracy of:  0.6912962962962963\n",
            "Norm:  [0.08578759 0.03021615]\n",
            "Epoch:  824  with accuracy of:  0.6916666666666667\n",
            "Norm:  [0.08564434 0.03017213]\n",
            "Epoch:  825  with accuracy of:  0.6916666666666667\n",
            "Norm:  [0.08552156 0.03012837]\n",
            "Epoch:  826  with accuracy of:  0.6918518518518518\n",
            "Norm:  [0.08540224 0.03008481]\n",
            "Epoch:  827  with accuracy of:  0.6918518518518518\n",
            "Norm:  [0.085317   0.03004155]\n",
            "Epoch:  828  with accuracy of:  0.692037037037037\n",
            "Norm:  [0.08517443 0.02999819]\n",
            "Epoch:  829  with accuracy of:  0.6918518518518518\n",
            "Norm:  [0.0850438  0.02995513]\n",
            "Epoch:  830  with accuracy of:  0.692037037037037\n",
            "Norm:  [0.08490822 0.02991281]\n",
            "Epoch:  831  with accuracy of:  0.6924074074074074\n",
            "Norm:  [0.08480935 0.0298703 ]\n",
            "Epoch:  832  with accuracy of:  0.6924074074074074\n",
            "Norm:  [0.08471027 0.0298279 ]\n",
            "Epoch:  833  with accuracy of:  0.6924074074074074\n",
            "Norm:  [0.0846504  0.02978559]\n",
            "Epoch:  834  with accuracy of:  0.6924074074074074\n",
            "Norm:  [0.08452136 0.02974324]\n",
            "Epoch:  835  with accuracy of:  0.6927777777777778\n",
            "Norm:  [0.08441999 0.02970102]\n",
            "Epoch:  836  with accuracy of:  0.6933333333333334\n",
            "Norm:  [0.08426931 0.02965899]\n",
            "Epoch:  837  with accuracy of:  0.6933333333333334\n",
            "Norm:  [0.08411963 0.0296171 ]\n",
            "Epoch:  838  with accuracy of:  0.6935185185185185\n",
            "Norm:  [0.08397386 0.02957585]\n",
            "Epoch:  839  with accuracy of:  0.6935185185185185\n",
            "Norm:  [0.08386607 0.02953485]\n",
            "Epoch:  840  with accuracy of:  0.6937037037037037\n",
            "Norm:  [0.08369613 0.0294946 ]\n",
            "Epoch:  841  with accuracy of:  0.6940740740740741\n",
            "Norm:  [0.0836365  0.02945456]\n",
            "Epoch:  842  with accuracy of:  0.6940740740740741\n",
            "Norm:  [0.08354046 0.02941483]\n",
            "Epoch:  843  with accuracy of:  0.6942592592592592\n",
            "Norm:  [0.08341715 0.02937521]\n",
            "Epoch:  844  with accuracy of:  0.6942592592592592\n",
            "Norm:  [0.08329641 0.02933576]\n",
            "Epoch:  845  with accuracy of:  0.6942592592592592\n",
            "Norm:  [0.0831711  0.02929653]\n",
            "Epoch:  846  with accuracy of:  0.6942592592592592\n",
            "Norm:  [0.08308095 0.02925747]\n",
            "Epoch:  847  with accuracy of:  0.6944444444444444\n",
            "Norm:  [0.08298119 0.02921862]\n",
            "Epoch:  848  with accuracy of:  0.6946296296296296\n",
            "Norm:  [0.08287792 0.02917982]\n",
            "Epoch:  849  with accuracy of:  0.6948148148148148\n",
            "Norm:  [0.08273884 0.0291414 ]\n",
            "Epoch:  850  with accuracy of:  0.6951851851851852\n",
            "Norm:  [0.08261524 0.02910304]\n",
            "Epoch:  851  with accuracy of:  0.6951851851851852\n",
            "Norm:  [0.0824923  0.02906473]\n",
            "Epoch:  852  with accuracy of:  0.6955555555555556\n",
            "Norm:  [0.08239775 0.02902651]\n",
            "Epoch:  853  with accuracy of:  0.6957407407407408\n",
            "Norm:  [0.08226899 0.0289885 ]\n",
            "Epoch:  854  with accuracy of:  0.6964814814814815\n",
            "Norm:  [0.08215481 0.02895022]\n",
            "Epoch:  855  with accuracy of:  0.6964814814814815\n",
            "Norm:  [0.08208004 0.02891189]\n",
            "Epoch:  856  with accuracy of:  0.6964814814814815\n",
            "Norm:  [0.08204096 0.02887389]\n",
            "Epoch:  857  with accuracy of:  0.6966666666666667\n",
            "Norm:  [0.08194244 0.02883645]\n",
            "Epoch:  858  with accuracy of:  0.6966666666666667\n",
            "Norm:  [0.08183869 0.02879913]\n",
            "Epoch:  859  with accuracy of:  0.6966666666666667\n",
            "Norm:  [0.08172079 0.02876223]\n",
            "Epoch:  860  with accuracy of:  0.697037037037037\n",
            "Norm:  [0.08162325 0.0287255 ]\n",
            "Epoch:  861  with accuracy of:  0.697037037037037\n",
            "Norm:  [0.08155381 0.02868898]\n",
            "Epoch:  862  with accuracy of:  0.6966666666666667\n",
            "Norm:  [0.08147114 0.02865292]\n",
            "Epoch:  863  with accuracy of:  0.6966666666666667\n",
            "Norm:  [0.0813923  0.02861679]\n",
            "Epoch:  864  with accuracy of:  0.6966666666666667\n",
            "Norm:  [0.08130527 0.02858077]\n",
            "Epoch:  865  with accuracy of:  0.6964814814814815\n",
            "Norm:  [0.08119167 0.02854488]\n",
            "Epoch:  866  with accuracy of:  0.6966666666666667\n",
            "Norm:  [0.08109987 0.02850942]\n",
            "Epoch:  867  with accuracy of:  0.6968518518518518\n",
            "Norm:  [0.08095289 0.02847374]\n",
            "Epoch:  868  with accuracy of:  0.6972222222222222\n",
            "Norm:  [0.08089921 0.028438  ]\n",
            "Epoch:  869  with accuracy of:  0.697037037037037\n",
            "Norm:  [0.08083129 0.0284026 ]\n",
            "Epoch:  870  with accuracy of:  0.6975925925925925\n",
            "Norm:  [0.08076944 0.02836719]\n",
            "Epoch:  871  with accuracy of:  0.6975925925925925\n",
            "Norm:  [0.08068665 0.02833179]\n",
            "Epoch:  872  with accuracy of:  0.6974074074074074\n",
            "Norm:  [0.08060316 0.02829636]\n",
            "Epoch:  873  with accuracy of:  0.697962962962963\n",
            "Norm:  [0.08044931 0.02826097]\n",
            "Epoch:  874  with accuracy of:  0.6981481481481482\n",
            "Norm:  [0.08030476 0.02822566]\n",
            "Epoch:  875  with accuracy of:  0.6981481481481482\n",
            "Norm:  [0.08021116 0.02819046]\n",
            "Epoch:  876  with accuracy of:  0.697962962962963\n",
            "Norm:  [0.08012572 0.02815549]\n",
            "Epoch:  877  with accuracy of:  0.6981481481481482\n",
            "Norm:  [0.07999658 0.02812067]\n",
            "Epoch:  878  with accuracy of:  0.6983333333333334\n",
            "Norm:  [0.07992692 0.02808589]\n",
            "Epoch:  879  with accuracy of:  0.6985185185185185\n",
            "Norm:  [0.07981967 0.02805125]\n",
            "Epoch:  880  with accuracy of:  0.6985185185185185\n",
            "Norm:  [0.07976028 0.02801671]\n",
            "Epoch:  881  with accuracy of:  0.6988888888888889\n",
            "Norm:  [0.07962128 0.02798187]\n",
            "Epoch:  882  with accuracy of:  0.6988888888888889\n",
            "Norm:  [0.07959859 0.02794661]\n",
            "Epoch:  883  with accuracy of:  0.6990740740740741\n",
            "Norm:  [0.07949388 0.02791138]\n",
            "Epoch:  884  with accuracy of:  0.6990740740740741\n",
            "Norm:  [0.07934832 0.02787643]\n",
            "Epoch:  885  with accuracy of:  0.6994444444444444\n",
            "Norm:  [0.0792663  0.02784142]\n",
            "Epoch:  886  with accuracy of:  0.6994444444444444\n",
            "Norm:  [0.07921736 0.02780654]\n",
            "Epoch:  887  with accuracy of:  0.6996296296296296\n",
            "Norm:  [0.07911711 0.02777203]\n",
            "Epoch:  888  with accuracy of:  0.6996296296296296\n",
            "Norm:  [0.07903293 0.02773777]\n",
            "Epoch:  889  with accuracy of:  0.6998148148148148\n",
            "Norm:  [0.07893068 0.02770344]\n",
            "Epoch:  890  with accuracy of:  0.6996296296296296\n",
            "Norm:  [0.07883185 0.02766951]\n",
            "Epoch:  891  with accuracy of:  0.7001851851851851\n",
            "Norm:  [0.07870695 0.02763575]\n",
            "Epoch:  892  with accuracy of:  0.7001851851851851\n",
            "Norm:  [0.0785819  0.02760216]\n",
            "Epoch:  893  with accuracy of:  0.7003703703703704\n",
            "Norm:  [0.07848698 0.0275684 ]\n",
            "Epoch:  894  with accuracy of:  0.7005555555555556\n",
            "Norm:  [0.07838926 0.02753489]\n",
            "Epoch:  895  with accuracy of:  0.7005555555555556\n",
            "Norm:  [0.0783893  0.02750164]\n",
            "Epoch:  896  with accuracy of:  0.7007407407407408\n",
            "Norm:  [0.0783463 0.0274684]\n",
            "Epoch:  897  with accuracy of:  0.700925925925926\n",
            "Norm:  [0.07821293 0.02743524]\n",
            "Epoch:  898  with accuracy of:  0.7011111111111111\n",
            "Norm:  [0.0781288  0.02740167]\n",
            "Epoch:  899  with accuracy of:  0.700925925925926\n",
            "Norm:  [0.07801215 0.02736833]\n",
            "Epoch:  900  with accuracy of:  0.700925925925926\n",
            "Norm:  [0.07791513 0.02733534]\n",
            "Epoch:  901  with accuracy of:  0.700925925925926\n",
            "Norm:  [0.07786835 0.02730249]\n",
            "Epoch:  902  with accuracy of:  0.700925925925926\n",
            "Norm:  [0.07776549 0.02726997]\n",
            "Epoch:  903  with accuracy of:  0.7011111111111111\n",
            "Norm:  [0.07762041 0.02723744]\n",
            "Epoch:  904  with accuracy of:  0.7012962962962963\n",
            "Norm:  [0.07754297 0.02720498]\n",
            "Epoch:  905  with accuracy of:  0.7012962962962963\n",
            "Norm:  [0.07747466 0.02717269]\n",
            "Epoch:  906  with accuracy of:  0.7014814814814815\n",
            "Norm:  [0.07737945 0.02714027]\n",
            "Epoch:  907  with accuracy of:  0.7014814814814815\n",
            "Norm:  [0.07737184 0.02710843]\n",
            "Epoch:  908  with accuracy of:  0.7014814814814815\n",
            "Norm:  [0.07730072 0.02707706]\n",
            "Epoch:  909  with accuracy of:  0.7016666666666667\n",
            "Norm:  [0.07719515 0.02704592]\n",
            "Epoch:  910  with accuracy of:  0.7018518518518518\n",
            "Norm:  [0.0770808  0.02701498]\n",
            "Epoch:  911  with accuracy of:  0.7018518518518518\n",
            "Norm:  [0.07699781 0.02698406]\n",
            "Epoch:  912  with accuracy of:  0.702037037037037\n",
            "Norm:  [0.07694969 0.02695338]\n",
            "Epoch:  913  with accuracy of:  0.702037037037037\n",
            "Norm:  [0.07686807 0.02692289]\n",
            "Epoch:  914  with accuracy of:  0.702037037037037\n",
            "Norm:  [0.0767672  0.02689253]\n",
            "Epoch:  915  with accuracy of:  0.702037037037037\n",
            "Norm:  [0.0767212  0.02686212]\n",
            "Epoch:  916  with accuracy of:  0.702037037037037\n",
            "Norm:  [0.0766663  0.02683204]\n",
            "Epoch:  917  with accuracy of:  0.702037037037037\n",
            "Norm:  [0.07658674 0.02680221]\n",
            "Epoch:  918  with accuracy of:  0.7022222222222222\n",
            "Norm:  [0.07649532 0.0267723 ]\n",
            "Epoch:  919  with accuracy of:  0.7025925925925925\n",
            "Norm:  [0.07643391 0.02674232]\n",
            "Epoch:  920  with accuracy of:  0.7025925925925925\n",
            "Norm:  [0.07635382 0.02671227]\n",
            "Epoch:  921  with accuracy of:  0.7025925925925925\n",
            "Norm:  [0.07623182 0.02668236]\n",
            "Epoch:  922  with accuracy of:  0.7027777777777777\n",
            "Norm:  [0.07609628 0.02665241]\n",
            "Epoch:  923  with accuracy of:  0.7027777777777777\n",
            "Norm:  [0.07597315 0.02662244]\n",
            "Epoch:  924  with accuracy of:  0.7027777777777777\n",
            "Norm:  [0.07588089 0.02659259]\n",
            "Epoch:  925  with accuracy of:  0.7027777777777777\n",
            "Norm:  [0.07577131 0.02656309]\n",
            "Epoch:  926  with accuracy of:  0.7027777777777777\n",
            "Norm:  [0.0756735  0.02653351]\n",
            "Epoch:  927  with accuracy of:  0.702962962962963\n",
            "Norm:  [0.07563853 0.02650401]\n",
            "Epoch:  928  with accuracy of:  0.7033333333333334\n",
            "Norm:  [0.07557052 0.02647475]\n",
            "Epoch:  929  with accuracy of:  0.7033333333333334\n",
            "Norm:  [0.07550267 0.0264457 ]\n",
            "Epoch:  930  with accuracy of:  0.7037037037037037\n",
            "Norm:  [0.07545662 0.02641665]\n",
            "Epoch:  931  with accuracy of:  0.7037037037037037\n",
            "Norm:  [0.07537164 0.02638787]\n",
            "Epoch:  932  with accuracy of:  0.7037037037037037\n",
            "Norm:  [0.07527798 0.0263594 ]\n",
            "Epoch:  933  with accuracy of:  0.7038888888888889\n",
            "Norm:  [0.07519696 0.02633099]\n",
            "Epoch:  934  with accuracy of:  0.7042592592592593\n",
            "Norm:  [0.07510127 0.0263026 ]\n",
            "Epoch:  935  with accuracy of:  0.7044444444444444\n",
            "Norm:  [0.07502016 0.02627396]\n",
            "Epoch:  936  with accuracy of:  0.7044444444444444\n",
            "Norm:  [0.0749428  0.02624527]\n",
            "Epoch:  937  with accuracy of:  0.7044444444444444\n",
            "Norm:  [0.07490541 0.02621661]\n",
            "Epoch:  938  with accuracy of:  0.7044444444444444\n",
            "Norm:  [0.0748705  0.02618815]\n",
            "Epoch:  939  with accuracy of:  0.7048148148148148\n",
            "Norm:  [0.07476142 0.02615979]\n",
            "Epoch:  940  with accuracy of:  0.705\n",
            "Norm:  [0.07465982 0.02613172]\n",
            "Epoch:  941  with accuracy of:  0.7053703703703704\n",
            "Norm:  [0.07457642 0.02610364]\n",
            "Epoch:  942  with accuracy of:  0.7053703703703704\n",
            "Norm:  [0.07449953 0.0260758 ]\n",
            "Epoch:  943  with accuracy of:  0.7055555555555556\n",
            "Norm:  [0.07442769 0.02604829]\n",
            "Epoch:  944  with accuracy of:  0.7055555555555556\n",
            "Norm:  [0.07435055 0.02602094]\n",
            "Epoch:  945  with accuracy of:  0.705925925925926\n",
            "Norm:  [0.07427649 0.02599366]\n",
            "Epoch:  946  with accuracy of:  0.7061111111111111\n",
            "Norm:  [0.07421535 0.0259666 ]\n",
            "Epoch:  947  with accuracy of:  0.7061111111111111\n",
            "Norm:  [0.07414936 0.02593993]\n",
            "Epoch:  948  with accuracy of:  0.7062962962962963\n",
            "Norm:  [0.07405779 0.02591329]\n",
            "Epoch:  949  with accuracy of:  0.7064814814814815\n",
            "Norm:  [0.07394587 0.02588672]\n",
            "Epoch:  950  with accuracy of:  0.7066666666666667\n",
            "Norm:  [0.07383009 0.0258602 ]\n",
            "Epoch:  951  with accuracy of:  0.7068518518518518\n",
            "Norm:  [0.07376717 0.02583344]\n",
            "Epoch:  952  with accuracy of:  0.707037037037037\n",
            "Norm:  [0.07369707 0.02580675]\n",
            "Epoch:  953  with accuracy of:  0.7072222222222222\n",
            "Norm:  [0.07363447 0.02578026]\n",
            "Epoch:  954  with accuracy of:  0.7075925925925926\n",
            "Norm:  [0.07357772 0.0257539 ]\n",
            "Epoch:  955  with accuracy of:  0.7075925925925926\n",
            "Norm:  [0.07347939 0.02572781]\n",
            "Epoch:  956  with accuracy of:  0.7077777777777777\n",
            "Norm:  [0.0733969  0.02570191]\n",
            "Epoch:  957  with accuracy of:  0.7077777777777777\n",
            "Norm:  [0.07328323 0.02567597]\n",
            "Epoch:  958  with accuracy of:  0.7077777777777777\n",
            "Norm:  [0.07319933 0.02564994]\n",
            "Epoch:  959  with accuracy of:  0.707962962962963\n",
            "Norm:  [0.07311172 0.02562396]\n",
            "Epoch:  960  with accuracy of:  0.707962962962963\n",
            "Norm:  [0.0730491  0.02559825]\n",
            "Epoch:  961  with accuracy of:  0.7083333333333334\n",
            "Norm:  [0.07299829 0.0255723 ]\n",
            "Epoch:  962  with accuracy of:  0.7083333333333334\n",
            "Norm:  [0.07286405 0.02554662]\n",
            "Epoch:  963  with accuracy of:  0.7083333333333334\n",
            "Norm:  [0.07280699 0.025521  ]\n",
            "Epoch:  964  with accuracy of:  0.7083333333333334\n",
            "Norm:  [0.07270513 0.02549547]\n",
            "Epoch:  965  with accuracy of:  0.7083333333333334\n",
            "Norm:  [0.07264086 0.02546985]\n",
            "Epoch:  966  with accuracy of:  0.7087037037037037\n",
            "Norm:  [0.07259349 0.0254443 ]\n",
            "Epoch:  967  with accuracy of:  0.7088888888888889\n",
            "Norm:  [0.07251482 0.02541891]\n",
            "Epoch:  968  with accuracy of:  0.7090740740740741\n",
            "Norm:  [0.07243533 0.02539387]\n",
            "Epoch:  969  with accuracy of:  0.7092592592592593\n",
            "Norm:  [0.07239459 0.02536899]\n",
            "Epoch:  970  with accuracy of:  0.7094444444444444\n",
            "Norm:  [0.0723566  0.02534412]\n",
            "Epoch:  971  with accuracy of:  0.7096296296296296\n",
            "Norm:  [0.07229679 0.02531955]\n",
            "Epoch:  972  with accuracy of:  0.7094444444444444\n",
            "Norm:  [0.07231999 0.02529482]\n",
            "Epoch:  973  with accuracy of:  0.7096296296296296\n",
            "Norm:  [0.07224359 0.02527029]\n",
            "Epoch:  974  with accuracy of:  0.7098148148148148\n",
            "Norm:  [0.07219139 0.02524567]\n",
            "Epoch:  975  with accuracy of:  0.7096296296296296\n",
            "Norm:  [0.07210817 0.02522099]\n",
            "Epoch:  976  with accuracy of:  0.7096296296296296\n",
            "Norm:  [0.07201005 0.02519622]\n",
            "Epoch:  977  with accuracy of:  0.7098148148148148\n",
            "Norm:  [0.07191433 0.02517146]\n",
            "Epoch:  978  with accuracy of:  0.7098148148148148\n",
            "Norm:  [0.07183922 0.02514668]\n",
            "Epoch:  979  with accuracy of:  0.71\n",
            "Norm:  [0.07175516 0.02512205]\n",
            "Epoch:  980  with accuracy of:  0.71\n",
            "Norm:  [0.07165793 0.02509742]\n",
            "Epoch:  981  with accuracy of:  0.71\n",
            "Norm:  [0.07161767 0.02507272]\n",
            "Epoch:  982  with accuracy of:  0.7105555555555556\n",
            "Norm:  [0.07155758 0.0250481 ]\n",
            "Epoch:  983  with accuracy of:  0.7105555555555556\n",
            "Norm:  [0.07149149 0.02502366]\n",
            "Epoch:  984  with accuracy of:  0.710925925925926\n",
            "Norm:  [0.07138917 0.0249993 ]\n",
            "Epoch:  985  with accuracy of:  0.7111111111111111\n",
            "Norm:  [0.07132058 0.02497506]\n",
            "Epoch:  986  with accuracy of:  0.7111111111111111\n",
            "Norm:  [0.07126256 0.02495082]\n",
            "Epoch:  987  with accuracy of:  0.7112962962962963\n",
            "Norm:  [0.07120169 0.02492674]\n",
            "Epoch:  988  with accuracy of:  0.7112962962962963\n",
            "Norm:  [0.07115692 0.02490264]\n",
            "Epoch:  989  with accuracy of:  0.7112962962962963\n",
            "Norm:  [0.07106945 0.02487842]\n",
            "Epoch:  990  with accuracy of:  0.7112962962962963\n",
            "Norm:  [0.07101662 0.02485447]\n",
            "Epoch:  991  with accuracy of:  0.7112962962962963\n",
            "Norm:  [0.07096206 0.02483068]\n",
            "Epoch:  992  with accuracy of:  0.7114814814814815\n",
            "Norm:  [0.07087983 0.02480711]\n",
            "Epoch:  993  with accuracy of:  0.7114814814814815\n",
            "Norm:  [0.07084624 0.02478363]\n",
            "Epoch:  994  with accuracy of:  0.7114814814814815\n",
            "Norm:  [0.0708009  0.02476044]\n",
            "Epoch:  995  with accuracy of:  0.7114814814814815\n",
            "Norm:  [0.07074469 0.0247373 ]\n",
            "Epoch:  996  with accuracy of:  0.7114814814814815\n",
            "Norm:  [0.07064827 0.02471433]\n",
            "Epoch:  997  with accuracy of:  0.712037037037037\n",
            "Norm:  [0.07057349 0.02469155]\n",
            "Epoch:  998  with accuracy of:  0.712037037037037\n",
            "Norm:  [0.07050165 0.02466864]\n",
            "Epoch:  999  with accuracy of:  0.712037037037037\n",
            "Norm:  [0.07043479 0.02464566]\n"
          ]
        }
      ],
      "source": [
        "mlp = MLP(x_test.shape[1], np.max(y_test)+1, epsilon=1e-3, activation=\"relu\")\n",
        "# pdb.set_trace()\n",
        "mlp.fit(x_train, y_train)\n",
        "yh = mlp.predict(x_test)\n",
        "\n",
        "# optimizer = GradientDescent(learning_rate=1e-2, max_iters=1e3)\n",
        "\n",
        "# yh = mlp.fit(x_train, y_train, optimizer, hidden_layer=1).predict(x_test)\n",
        "# print(\"\\n\\nAccuracy of validation set is: %.3f\\n\\n\" % eval_acc(np.array(yh), np.array(y_test)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Group 18 - Miniproject 3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMMk2MFhNTNubY0aujPXONZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}